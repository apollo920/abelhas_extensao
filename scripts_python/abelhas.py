#!/usr/bin/env python
# coding: utf-8

# ## Algoritmo Random Forest
# - Previs√£o do posicionamento da Abelha Trigona Spinipes no per√≠odo de 2021-2040, 2041-2060, 2061-80 e 2081-2100

# ### Configura√ß√£o de Ambiente 
# 

# In[122]:


# Instalar depend√™ncias necess√°rias
# pip install pandas geopandas rasterio scikit-learn matplotlib streamlit folium streamlit-folium


# In[123]:


# Importar bibliotecas (adicionando pathlib)
import pandas as pd
import geopandas as gpd
import numpy as np
import rasterio
from rasterio.plot import show
from rasterio.features import geometry_mask
import glob
import os
from pathlib import Path  # <<< IMPORTAMOS A BIBLIOTECA PATHLIB
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import warnings

# Ignorar avisos para uma sa√≠da mais limpa
warnings.filterwarnings('ignore')

# --- DEFINI√á√ÉO AUTOM√ÅTICA DOS CAMINHOS ---
# Esta linha m√°gica encontra o caminho da pasta do projeto automaticamente!
# Path.cwd() pega o diret√≥rio atual (.../abelhas_extensao/notebooks)
# .parent sobe um n√≠vel (.../abelhas_extensao)
BASE_DIR = Path.cwd()

# Definir os caminhos completos usando o operador / do pathlib
OCORRENCIAS_PATH = BASE_DIR / 'data' / 'ocorrencias.csv'
CLIMA_ATUAL_PATH = BASE_DIR / 'data' / 'clima_atual'
BRASIL_SHAPE_PATH = BASE_DIR / 'data' / 'BR_UF_2024'
PASTA_PREVISOES = BASE_DIR / 'data' / 'previsoes_futuras'

# Criar a pasta para salvar as previs√µes, se ela n√£o existir
PASTA_PREVISOES.mkdir(parents=True, exist_ok=True)

print("Ambiente configurado e caminhos definidos automaticamente com pathlib!")
print(f"Pasta raiz do projeto encontrada: {BASE_DIR}")
print(f"Caminho do arquivo de ocorr√™ncias: {OCORRENCIAS_PATH}")


# ### Tratamento e Carregamento dos Dados
# 

# #### Carregar Dados de Ocorr√™ncia e Mapa do Brasil

# In[124]:


# Carregar dados de ocorr√™ncia de forma robusta (VERS√ÉO FINAL CORRIGIDA)
try:
    print("Tentando carregar o arquivo 'ocorrencias.csv'...")
    ocorrencias_df_full = pd.read_csv(
        OCORRENCIAS_PATH,
        sep='\t',                     # <<< A MUDAN√áA CHAVE! Diz ao pandas para usar tabula√ß√£o como separador.
        comment='#',
        on_bad_lines='skip',
        low_memory=False,
        encoding='utf-8-sig'
    )

    # Agora, selecionamos apenas as colunas que nos interessamos e removemos valores nulos
    ocorrencias_df = ocorrencias_df_full[['decimalLatitude', 'decimalLongitude']].dropna()

    print("‚úÖ Arquivo carregado com sucesso!")
    print(f"Total de pontos de ocorr√™ncia carregados: {len(ocorrencias_df)}")
    print(ocorrencias_df.head())

except FileNotFoundError:
    print(f"‚ùå Erro: Arquivo n√£o encontrado em '{OCORRENCIAS_PATH}'. Verifique se o caminho est√° correto.")
except KeyError:
    print("‚ùå Erro: As colunas 'decimalLatitude' ou 'decimalLongitude' n√£o foram encontradas no arquivo.")
    print("Verifique os nomes das colunas no cabe√ßalho do seu CSV.")
except Exception as e:
    print(f"‚ùå Ocorreu um erro inesperado ao carregar o arquivo: {e}")

# Converter o DataFrame para um GeoDataFrame
gdf_ocorrencias = gpd.GeoDataFrame(
    ocorrencias_df,
    geometry=gpd.points_from_xy(ocorrencias_df.decimalLongitude, ocorrencias_df.decimalLatitude),
    crs="EPSG:4326"
)

# Carregar o mapa do Brasil (shapefile)
shapefile_brasil = glob.glob(os.path.join(BRASIL_SHAPE_PATH, "*.shp"))[0]
brasil_gdf = gpd.read_file(shapefile_brasil)

# Unir todos os estados em um √∫nico pol√≠gono do Brasil
brasil_poligono = brasil_gdf.unary_union

print("\nMapa do Brasil e pontos de ocorr√™ncia carregados com sucesso.")


# #### Carregar e empilhar Dados Clim√°ticos Atuais 

# In[125]:


# Listar todos os arquivos .tif de clima atual, em ordem alfab√©tica
clima_files = sorted(glob.glob(os.path.join(CLIMA_ATUAL_PATH, "*.tif")))

# Abrir o primeiro arquivo para obter metadados
with rasterio.open(clima_files[0]) as src:
    meta = src.meta

# Atualizar os metadados para o novo raster empilhado (agora com 19 bandas)
meta.update(count=len(clima_files))

# Criar o caminho para o arquivo empilhado
stack_path = os.path.join(CLIMA_ATUAL_PATH, "clima_atual_stack.tif")

# Empilhar os rasters em um √∫nico arquivo
with rasterio.open(stack_path, 'w', **meta) as dst:
    for i, file in enumerate(clima_files, 1):
        with rasterio.open(file) as src:
            dst.write(src.read(1), i)

print(f"Rasters clim√°ticos atuais empilhados em: {stack_path}")


# #### Gerar Dados de Pseudo-Aus√™ncia
# - Geramos pontos de pseudo-aus√™ncia em √°reas aleat√≥rias, mas longe dos pontos de presen√ßa, para treinar o modelo.

# In[126]:


# --- VERS√ÉO MELHORADA PARA GERAR PSEUDO-AUS√äNCIAS ---
from shapely.geometry import Point

# N√∫mero de pontos de pseudo-aus√™ncia (mantemos o mesmo n√∫mero)
num_pseudo_ausencias = len(gdf_ocorrencias) * 2

# Isso torna a tarefa de classifica√ß√£o mais realista e desafiadora
pseudo_ausencias_points = []
while len(pseudo_ausencias_points) < num_pseudo_ausencias:
    # Obter limites geogr√°ficos do Brasil
    minx, miny, maxx, maxy = brasil_poligono.bounds

    # Gerar um ponto aleat√≥rio dentro desses limites
    random_point = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))

    # Verificar se o ponto est√° dentro do Brasil (sem a verifica√ß√£o de buffer)
    if brasil_poligono.contains(random_point):
        pseudo_ausencias_points.append(random_point)

# Criar um GeoDataFrame para as pseudo-aus√™ncias
gdf_pseudo_ausencias = gpd.GeoDataFrame(
    geometry=pseudo_ausencias_points,
    crs="EPSG:4326"
)

print(f"Gerados {len(gdf_pseudo_ausencias)} pontos de pseudo-aus√™ncia realistas em todo o Brasil.")


# #### Criar um Conjunto de Dados de Treinamento Final

# In[127]:

def load_brazil_map_notebook(path):
    """Fun√ß√£o auxiliar para carregar o GeoDataFrame do Brasil."""
    shapefile_brasil = glob.glob(os.path.join(path, "*.shp"))[0]
    brasil_gdf = gpd.read_file(shapefile_brasil)
    # Garante que o CRS seja compat√≠vel com os rasters (EPSG:4326)
    if brasil_gdf.crs != "EPSG:4326":
        brasil_gdf = brasil_gdf.to_crs("EPSG:4326")
    return brasil_gdf

# Fun√ß√£o para extrair valores do raster para um GeoDataFrame
def extract_raster_values(gdf, raster_path):
    with rasterio.open(raster_path) as src:
        coords = [(x, y) for x, y in zip(gdf.geometry.x, gdf.geometry.y)]
        values = [val for val in src.sample(coords)]
    return np.array(values)

# Extrair valores para presen√ßas e pseudo-aus√™ncias
valores_presenca = extract_raster_values(gdf_ocorrencias, stack_path)
valores_ausencia = extract_raster_values(gdf_pseudo_ausencias, stack_path)

# Criar o dataset final
X = np.vstack((valores_presenca, valores_ausencia))
y = np.array([1] * len(valores_presenca) + [0] * len(valores_ausencia))

# Nomes das features (bio1 a bio19)
feature_names = [os.path.basename(f).split('.')[0] for f in sorted(clima_files)]

# Criar um DataFrame para visualiza√ß√£o
df_treinamento = pd.DataFrame(X, columns=feature_names)
df_treinamento['presenca'] = y

print("Conjunto de dados de treinamento criado:")
print(df_treinamento.head())
print(f"\nShape de X: {X.shape}, Shape de y: {y.shape}")


# ### Treinamento do Modelo Random Forest
# 

# #### Dividir os Dados e Treinar o Modelo

# In[128]:


# --- VERS√ÉO MELHORADA: TREINAMENTO E AVALIA√á√ÉO ROBUSTA ---

# Preparar os dados de treino (mesmo c√≥digo de antes)
valores_presenca = extract_raster_values(gdf_ocorrencias, stack_path)
valores_ausencia = extract_raster_values(gdf_pseudo_ausencias, stack_path)
X = np.vstack((valores_presenca, valores_ausencia))
y = np.array([1] * len(valores_presenca) + [0] * len(valores_ausencia))

# --- Valida√ß√£o Cruzada para uma Avalia√ß√£o Mais Confi√°vel ---
from sklearn.model_selection import StratifiedKFold, cross_val_score

# Inicializar o modelo com par√¢metros para reduzir overfitting
# max_depth: limita a profundidade das √°rvores
# min_samples_leaf: exige um n√∫mero m√≠nimo de amostras em uma folha
rf_model = RandomForestClassifier(
    n_estimators=200, 
    random_state=42, 
    n_jobs=-1, 
    class_weight='balanced',
    max_depth=15,          # <<< NOVO: Limita a complexidade
    min_samples_leaf=5     # <<< NOVO: Evita folhas muito espec√≠ficas
)

print("Avaliando o modelo com Valida√ß√£o Cruzada (5 folds)...")
# StratifiedKFold mant√©m a propor√ß√£o de classes em cada fold
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Calcular a acur√°cia em cada fold
scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')

print(f"\nAcur√°cias em cada fold: {scores}")
print(f"Acur√°cia M√©dia (CV): {scores.mean():.4f}")
print(f"Desvio Padr√£o da Acur√°cia: {scores.std():.4f}")

# Agora, treinamos o modelo final com TODOS os dados dispon√≠veis
print("\nTreinando o modelo final com todos os dados...")
rf_model.fit(X, y)
print("Modelo final treinado!")

# Analisar a import√¢ncia das vari√°veis (com o modelo final)
importancias = pd.DataFrame({
    'variavel': feature_names,
    'importancia': rf_model.feature_importances_
}).sort_values('importancia', ascending=False)

print("\nImport√¢ncia das Vari√°veis Clim√°ticas (modelo final):")
print(importancias)


# ### Previs√£o para cen√°rios futuros

# #### Definir a Fun√ß√£o de Previs√£o

# In[129]:


def prever_cenario_para_brasil(cenario_file_path, modelo, output_path):
    """
    Vers√£o final e corrigida: processa o raster global e recorta o resultado
    usando numpy, evitando o erro de arquivo fechado.
    """
    print(f"Processando o arquivo: {cenario_file_path.name}")

    # Carregar o mapa do Brasil
    brasil_gdf = load_brazil_map_notebook(BASE_DIR / 'data' / 'BR_UF_2024')

    # --- VERIFICA√á√ïES E CORRE√á√ïES ROBUSTAS ---
    if brasil_gdf.empty:
        raise ValueError("O GeoDataFrame do Brasil est√° vazio. Verifique o arquivo shapefile.")

    if not brasil_gdf.is_valid.all():
        print("Aviso: Encontradas geometrias inv√°lidas no shapefile. Tentando corrigir automaticamente...")
        brasil_gdf['geometry'] = brasil_gdf.geometry.buffer(0)
        if not brasil_gdf.is_valid.all():
            raise ValueError("N√£o foi poss√≠vel corrigir as geometrias inv√°lidas.")
        else:
            print("Geometrias corrigidas com sucesso.")

    # Abrir o raster para obter seu CRS e metadados
    with rasterio.open(cenario_file_path) as src:
        raster_crs = src.crs
        profile = src.profile

    # --- VERIFICA√á√ÉO E CORRE√á√ÉO DE CRS ---
    if brasil_gdf.crs != raster_crs:
        print(f"Aviso: CRS do shapefile ({brasil_gdf.crs}) √© diferente do CRS do raster ({raster_crs}).")
        print("Reprojetando o shapefile para o CRS do raster...")
        brasil_gdf = brasil_gdf.to_crs(raster_crs)
        print("Reproje√ß√£o conclu√≠da.")

    # Com o CRS alinhado, podemos calcular o pol√≠gono e os limites com seguran√ßa
    brasil_poligono = brasil_gdf.unary_union
    brasil_bounds = brasil_gdf.total_bounds

    # --- ESTRAT√âGIA ROBUSTA: LER TUDO, MASCARAR E DEPOIS RECORTAR ---
    with rasterio.open(cenario_file_path) as src:
        # 1. Ler o raster global inteiro
        raster_data = src.read()

        # 2. Criar a m√°scara global
        mask = geometry_mask(
            [brasil_poligono], 
            out_shape=src.shape, 
            transform=src.transform, 
            invert=False
        )

    # 3. Preparar os dados para o modelo
    height, width = raster_data.shape[1], raster_data.shape[2]
    raster_data_reshaped = raster_data.reshape((raster_data.shape[0], -1)).T
    mask_flat = mask.reshape(-1)

    dados_brasil = raster_data_reshaped[~mask_flat]

    # Tratar valores NoData
    nodata_val = profile['nodata']
    if nodata_val is not None:
        dados_brasil[dados_brasil == nodata_val] = np.nan

    col_mean = np.nanmean(dados_brasil, axis=0)
    inds = np.where(np.isnan(dados_brasil))
    dados_brasil[inds] = np.take(col_mean, inds[1])

    print("Realizando a previs√£o para a √°rea do Brasil...")
    previsao_brasil = modelo.predict_proba(dados_brasil)[:, 1]

    # 4. Reconstruir o mapa global (com NoData fora do Brasil)
    previsao_mapa_global = np.full(height * width, nodata_val, dtype=rasterio.float32)
    previsao_mapa_global[~mask_flat] = previsao_brasil
    previsao_mapa_global = previsao_mapa_global.reshape((height, width))

    # 5. RECORTAR O MAPA FINAL para o tamanho do Brasil
    # Criar uma janela de recorte usando as coordenadas do Brasil
    with rasterio.open(cenario_file_path) as src_recorte:
        # Criar janela com base nos limites do Brasil
        window_final = rasterio.windows.from_bounds(
            brasil_bounds[0], brasil_bounds[1], 
            brasil_bounds[2], brasil_bounds[3], 
            src_recorte.transform
        )

        # Calcular o novo transform para a janela recortada
        transform_recortado = src_recorte.window_transform(window_final)

    # Recortar o mapa de previs√£o usando √≠ndices da janela
    row_start = int(window_final.row_off)
    row_end = int(window_final.row_off + window_final.height)
    col_start = int(window_final.col_off)
    col_end = int(window_final.col_off + window_final.width)

    # Garantir que os √≠ndices n√£o saiam dos limites
    row_start = max(0, row_start)
    row_end = min(height, row_end)
    col_start = max(0, col_start)
    col_end = min(width, col_end)

    previsao_mapa_recortada = previsao_mapa_global[row_start:row_end, col_start:col_end]

    # Atualizar o perfil para o arquivo de sa√≠da (recortado)
    profile.update({
        'height': previsao_mapa_recortada.shape[0],
        'width': previsao_mapa_recortada.shape[1],
        'transform': transform_recortado,
        'dtype': rasterio.float32,
        'count': 1,
        'compress': 'lzw'
    })

    # Salvar o mapa de previs√£o recortado
    with rasterio.open(output_path, 'w', **profile) as dst:
        dst.write(previsao_mapa_recortada, 1)


# #### Executar as Previs√µes para todos os Per√≠odos 

# In[132]:


# --- EXECUTAR AS PREVIS√ïES (VERS√ÉO FOCADA NO BRASIL) ---

import time
from datetime import datetime

# O caminho para a pasta que cont√©m os arquivos .tif de cen√°rios futuros
cenario_files_path = BASE_DIR / 'data' / 'clima_futuro'

# Definir a ordem EXATA dos cen√°rios
ordem_dos_cenarios = [
    "wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040.tif",
    "wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060.tif",
    "wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080.tif",
    "wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100.tif"
]

print("=" * 80)
print("INICIANDO PROCESSAMENTO DOS CEN√ÅRIOS CLIM√ÅTICOS FUTUROS")
print("=" * 80)
print(f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
print(f"Total de cen√°rios: {len(ordem_dos_cenarios)}\n")

# Contador de sucessos e falhas
processados_com_sucesso = 0
falhas = []

# Timer geral
inicio_geral = time.time()

for idx, nome_do_arquivo in enumerate(ordem_dos_cenarios, 1):
    cenario_file = cenario_files_path / nome_do_arquivo

    print(f"\n{'‚îÄ' * 80}")
    print(f"[{idx}/{len(ordem_dos_cenarios)}] PROCESSANDO: {cenario_file.name}")
    print(f"{'‚îÄ' * 80}")

    if cenario_file.exists():
        try:
            # Timer individual
            inicio = time.time()

            # Definir nome do arquivo de sa√≠da
            periodo_nome = cenario_file.stem
            output_filename = f"previsao_trigona_{periodo_nome}.tif"
            output_path = PASTA_PREVISOES / output_filename

            # Chamar a fun√ß√£o de previs√£o
            prever_cenario_para_brasil(cenario_file, rf_model, output_path)

            # Calcular tempo de processamento
            tempo_decorrido = time.time() - inicio

            print(f"‚úÖ SUCESSO!")
            print(f"   ‚è±Ô∏è  Tempo: {tempo_decorrido:.2f} segundos")
            print(f"   üíæ Salvo em: {output_path.name}")

            processados_com_sucesso += 1

        except Exception as e:
            print(f"‚ùå ERRO ao processar {nome_do_arquivo}")
            print(f"   Detalhes: {str(e)}")
            falhas.append((nome_do_arquivo, str(e)))
    else:
        print(f"‚ö†Ô∏è  AVISO: Arquivo n√£o encontrado!")
        print(f"   Caminho esperado: {cenario_file}")
        falhas.append((nome_do_arquivo, "Arquivo n√£o encontrado"))

# Tempo total
tempo_total = time.time() - inicio_geral

# Relat√≥rio final
print("\n" + "=" * 80)
print("RELAT√ìRIO FINAL DO PROCESSAMENTO")
print("=" * 80)
print(f"‚úÖ Processados com sucesso: {processados_com_sucesso}/{len(ordem_dos_cenarios)}")
print(f"‚ùå Falhas: {len(falhas)}")
print(f"‚è±Ô∏è  Tempo total: {tempo_total:.2f} segundos ({tempo_total/60:.2f} minutos)")

if falhas:
    print("\n‚ö†Ô∏è  ARQUIVOS COM PROBLEMAS:")
    for arquivo, erro in falhas:
        print(f"   ‚Ä¢ {arquivo}")
        print(f"     Motivo: {erro}")
else:
    print("\nüéâ TODOS OS CEN√ÅRIOS FORAM PROCESSADOS COM SUCESSO!")

print(f"\nüíæ Localiza√ß√£o dos resultados:")
print(f"   {PASTA_PREVISOES}")
print("=" * 80)


# ### Visualiza√ß√£o da Previs√£o

# In[135]:


# --- VISUALIZAR TODOS OS MAPAS DE PREVIS√ÉO ---

import matplotlib.pyplot as plt
import matplotlib.colors as colors
import rasterio
from pathlib import Path

print("=" * 80)
print("GERANDO VISUALIZA√á√ïES DOS MAPAS DE PREVIS√ÉO")
print("=" * 80)

# Buscar todos os arquivos .tif na pasta de previs√µes
mapas_previsao = sorted(PASTA_PREVISOES.glob("previsao_trigona_*.tif"))

if not mapas_previsao:
    print("\n‚ö†Ô∏è  Nenhum mapa de previs√£o encontrado!")
    print(f"üìÅ Pasta verificada: {PASTA_PREVISOES}")
else:
    print(f"\n‚úÖ Encontrados {len(mapas_previsao)} mapas de previs√£o\n")

    # Carregar o mapa do Brasil (uma vez s√≥, para reaproveitar)
    brasil_gdf = load_brazil_map_notebook(BASE_DIR / 'data' / 'BR_UF_2024')
    brasil_bounds = brasil_gdf.total_bounds

    # Configura√ß√£o do mapa de cores
    cmap = plt.get_cmap('RdYlGn_r')
    norm = colors.Normalize(vmin=0, vmax=1)

    # =========================================================================
    # OP√á√ÉO 1: VISUALIZA√á√ÉO INDIVIDUAL (um mapa por vez, melhor qualidade)
    # =========================================================================
    print("üìä Op√ß√£o 1: Visualiza√ß√µes Individuais (alta qualidade)")
    print("-" * 80)

    for idx, mapa_path in enumerate(mapas_previsao, 1):
        print(f"[{idx}/{len(mapas_previsao)}] Processando: {mapa_path.name}")

        try:
            with rasterio.open(mapa_path) as src:
                previsao_data = src.read(1)

            # Extrair per√≠odo do nome do arquivo
            # Ex: "previsao_trigona_wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040.tif"
            nome_arquivo = mapa_path.stem
            if '2021-2040' in nome_arquivo:
                periodo = '2021-2040'
            elif '2041-2060' in nome_arquivo:
                periodo = '2041-2060'
            elif '2061-2080' in nome_arquivo:
                periodo = '2061-2080'
            elif '2081-2100' in nome_arquivo:
                periodo = '2081-2100'
            else:
                periodo = 'Per√≠odo Desconhecido'

            # Criar figura individual
            fig, ax = plt.subplots(figsize=(14, 12))

            # Plotar o raster
            im = ax.imshow(previsao_data, cmap=cmap, norm=norm, 
                          extent=[brasil_bounds[0], brasil_bounds[2], 
                                 brasil_bounds[1], brasil_bounds[3]])

            # Adicionar contorno do Brasil
            brasil_gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=0.8)

            # Configurar t√≠tulo e labels
            ax.set_title(f"Adequabilidade de Habitat - Trigona spinipes\nPer√≠odo: {periodo}", 
                        fontsize=18, fontweight='bold', pad=20)
            ax.set_xlabel("Longitude", fontsize=12)
            ax.set_ylabel("Latitude", fontsize=12)

            # Ajustar limites
            ax.set_xlim(brasil_bounds[0], brasil_bounds[2])
            ax.set_ylim(brasil_bounds[1], brasil_bounds[3])

            # Adicionar colorbar
            cbar = fig.colorbar(im, ax=ax, orientation='vertical', shrink=0.7, pad=0.02)
            cbar.set_label('Probabilidade de Adequabilidade', rotation=270, labelpad=25, fontsize=12)

            # Adicionar grid sutil
            ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)

            plt.tight_layout()
            plt.show()

            print(f"   ‚úÖ Visualizado com sucesso!\n")

        except Exception as e:
            print(f"   ‚ùå Erro ao processar: {str(e)}\n")

    # =========================================================================
    # OP√á√ÉO 2: VISUALIZA√á√ÉO COMPARATIVA (todos juntos em uma grid)
    # =========================================================================
    print("\n" + "=" * 80)
    print("üìä Op√ß√£o 2: Visualiza√ß√£o Comparativa (grid 2x2)")
    print("-" * 80)

    if len(mapas_previsao) >= 2:
        # Determinar layout da grid
        n_mapas = len(mapas_previsao)
        if n_mapas <= 2:
            nrows, ncols = 1, 2
        elif n_mapas <= 4:
            nrows, ncols = 2, 2
        else:
            nrows, ncols = 3, 2

        # Criar figura com subplots
        fig, axes = plt.subplots(nrows, ncols, figsize=(20, 18))
        axes = axes.flatten() if n_mapas > 1 else [axes]

        for idx, (mapa_path, ax) in enumerate(zip(mapas_previsao, axes)):
            try:
                with rasterio.open(mapa_path) as src:
                    previsao_data = src.read(1)

                # Extrair per√≠odo
                nome_arquivo = mapa_path.stem
                if '2021-2040' in nome_arquivo:
                    periodo = '2021-2040'
                elif '2041-2060' in nome_arquivo:
                    periodo = '2041-2060'
                elif '2061-2080' in nome_arquivo:
                    periodo = '2061-2080'
                elif '2081-2100' in nome_arquivo:
                    periodo = '2081-2100'
                else:
                    periodo = 'Per√≠odo Desconhecido'

                # Plotar
                im = ax.imshow(previsao_data, cmap=cmap, norm=norm,
                             extent=[brasil_bounds[0], brasil_bounds[2],
                                    brasil_bounds[1], brasil_bounds[3]])

                brasil_gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=0.6)

                ax.set_title(f"Per√≠odo: {periodo}", fontsize=14, fontweight='bold')
                ax.set_xlabel("Longitude", fontsize=10)
                ax.set_ylabel("Latitude", fontsize=10)
                ax.set_xlim(brasil_bounds[0], brasil_bounds[2])
                ax.set_ylim(brasil_bounds[1], brasil_bounds[3])
                ax.grid(True, alpha=0.2, linestyle='--', linewidth=0.3)

                print(f"   ‚úÖ [{idx+1}/{n_mapas}] {periodo}")

            except Exception as e:
                ax.text(0.5, 0.5, f'Erro ao carregar\n{mapa_path.name}', 
                       ha='center', va='center', transform=ax.transAxes)
                print(f"   ‚ùå Erro: {str(e)}")

        # Remover axes extras se houver
        for idx in range(len(mapas_previsao), len(axes)):
            fig.delaxes(axes[idx])

        # T√≠tulo geral
        fig.suptitle('Adequabilidade de Habitat - Trigona spinipes\nCompara√ß√£o entre Per√≠odos Futuros', 
                    fontsize=20, fontweight='bold', y=0.98)

        # Colorbar compartilhada
        cbar = fig.colorbar(im, ax=axes, orientation='vertical', 
                           fraction=0.02, pad=0.02, shrink=0.8)
        cbar.set_label('Probabilidade de Adequabilidade', 
                      rotation=270, labelpad=25, fontsize=14)

        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plt.show()

        print("\n‚úÖ Visualiza√ß√£o comparativa conclu√≠da!")
    else:
        print("‚ö†Ô∏è  Necess√°rio pelo menos 2 mapas para visualiza√ß√£o comparativa")

print("\n" + "=" * 80)
print("‚úÖ PROCESSO DE VISUALIZA√á√ÉO CONCLU√çDO!")
print("=" * 80)

