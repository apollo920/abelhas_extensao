{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb194a5",
   "metadata": {},
   "source": [
    "# Projeto Abelho Trigona Spinipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5ccfb",
   "metadata": {},
   "source": [
    "## Processar variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "def extrair_variaveis_bioclimaticas(arquivo_tif, diretorio_saida):\n",
    "    \"\"\"\n",
    "    Extrai as 19 variáveis bioclimáticas de um único arquivo .tif do WorldClim\n",
    "    e salva cada uma como um arquivo separado.\n",
    "    \n",
    "    Args:\n",
    "        arquivo_tif: Caminho para o arquivo .tif multi-banda do WorldClim\n",
    "        diretorio_saida: Diretório onde salvar os arquivos individuais\n",
    "    \"\"\"\n",
    "    os.makedirs(diretorio_saida, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processando arquivo: {arquivo_tif}\")\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(arquivo_tif) as src:\n",
    "            # Verificar número de bandas\n",
    "            num_bandas = src.count\n",
    "            print(f\"Número de bandas detectadas: {num_bandas}\")\n",
    "            \n",
    "            if num_bandas == 1:\n",
    "                print(\"AVISO: Este arquivo tem apenas uma banda. Pode não ser um arquivo multi-variável.\")\n",
    "                \n",
    "                # Extrair nome da variável do nome do arquivo\n",
    "                nome_arquivo = os.path.basename(arquivo_tif)\n",
    "                if \"bio\" in nome_arquivo.lower():\n",
    "                    # Tentar extrair número da variável bioclimática\n",
    "                    partes = nome_arquivo.lower().split(\"bio\")\n",
    "                    if len(partes) > 1:\n",
    "                        num_var = ''.join(filter(str.isdigit, partes[1]))\n",
    "                        if num_var:\n",
    "                            novo_nome = f\"bio{num_var}.tif\"\n",
    "                            arquivo_saida = os.path.join(diretorio_saida, novo_nome)\n",
    "                            \n",
    "                            # Copiar arquivo\n",
    "                            shutil.copy(arquivo_tif, arquivo_saida)\n",
    "                            print(f\"Copiado: {nome_arquivo} -> {novo_nome}\")\n",
    "                        else:\n",
    "                            print(f\"Não foi possível extrair número da variável de {nome_arquivo}\")\n",
    "                else:\n",
    "                    print(f\"Arquivo não parece ser uma variável bioclimática: {nome_arquivo}\")\n",
    "            else:\n",
    "                # Processar arquivo multi-banda\n",
    "                meta = src.meta.copy()\n",
    "                \n",
    "                # Atualizar metadados para arquivos de saída (uma banda)\n",
    "                meta.update({\n",
    "                    'count': 1,\n",
    "                    'driver': 'GTiff',\n",
    "                    'compress': 'lzw'\n",
    "                })\n",
    "                \n",
    "                # Extrair cada banda como um arquivo separado\n",
    "                for i in range(1, num_bandas + 1):\n",
    "                    banda = src.read(i)\n",
    "                    \n",
    "                    # Nome do arquivo de saída\n",
    "                    arquivo_saida = os.path.join(diretorio_saida, f\"bio{i}.tif\")\n",
    "                    \n",
    "                    # Salvar banda como arquivo separado\n",
    "                    with rasterio.open(arquivo_saida, 'w', **meta) as dst:\n",
    "                        dst.write(banda, 1)\n",
    "                    \n",
    "                    print(f\"Extraído: banda {i} -> bio{i}.tif\")\n",
    "                \n",
    "                print(f\"Extração concluída: {num_bandas} variáveis salvas em {diretorio_saida}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao processar {arquivo_tif}: {str(e)}\")\n",
    "\n",
    "def padronizar_nomes_arquivos(diretorio_origem, diretorio_destino):\n",
    "    \"\"\"\n",
    "    Padroniza os nomes dos arquivos .tif para o formato bio1.tif, bio2.tif, etc.\n",
    "    \n",
    "    Args:\n",
    "        diretorio_origem: Diretório com os arquivos originais\n",
    "        diretorio_destino: Diretório onde salvar os arquivos renomeados\n",
    "    \"\"\"\n",
    "    os.makedirs(diretorio_destino, exist_ok=True)\n",
    "    \n",
    "    print(f\"Padronizando nomes dos arquivos em {diretorio_origem}\")\n",
    "    \n",
    "    # Padrões de nomes conhecidos do WorldClim\n",
    "    padroes = [\n",
    "        # WorldClim v2.1\n",
    "        {\"prefixo\": \"wc2.1_\", \"separador\": \"bio\"},\n",
    "        # CMIP6\n",
    "        {\"prefixo\": \"ssp\", \"separador\": \"bio\"},\n",
    "        {\"prefixo\": \"rcp\", \"separador\": \"bio\"},\n",
    "        # Outros formatos possíveis\n",
    "        {\"prefixo\": \"\", \"separador\": \"bio\"}\n",
    "    ]\n",
    "    \n",
    "    arquivos_processados = 0\n",
    "    \n",
    "    for arquivo in glob.glob(os.path.join(diretorio_origem, \"*.tif\")):\n",
    "        nome_arquivo = os.path.basename(arquivo)\n",
    "        nome_base = os.path.splitext(nome_arquivo)[0]\n",
    "        \n",
    "        # Tentar extrair número da variável bioclimática\n",
    "        num_var = None\n",
    "        \n",
    "        for padrao in padroes:\n",
    "            if padrao[\"separador\"] in nome_base.lower():\n",
    "                partes = nome_base.lower().split(padrao[\"separador\"])\n",
    "                if len(partes) > 1:\n",
    "                    # Extrair dígitos do final\n",
    "                    num_var = ''.join(filter(str.isdigit, partes[1]))\n",
    "                    if num_var:\n",
    "                        break\n",
    "        \n",
    "        if num_var:\n",
    "            novo_nome = f\"bio{num_var}.tif\"\n",
    "            arquivo_saida = os.path.join(diretorio_destino, novo_nome)\n",
    "            \n",
    "            # Copiar arquivo com novo nome\n",
    "            shutil.copy(arquivo, arquivo_saida)\n",
    "            print(f\"Renomeado: {nome_arquivo} -> {novo_nome}\")\n",
    "            arquivos_processados += 1\n",
    "        else:\n",
    "            print(f\"Não foi possível extrair número da variável de {nome_arquivo}\")\n",
    "    \n",
    "    print(f\"Padronização concluída: {arquivos_processados} arquivos processados\")\n",
    "\n",
    "def verificar_consistencia(dir_atual, dir_futuro):\n",
    "    \"\"\"\n",
    "    Verifica se os mesmos arquivos existem em ambos os diretórios e têm as mesmas dimensões\n",
    "    \n",
    "    Args:\n",
    "        dir_atual: Diretório com variáveis do clima atual\n",
    "        dir_futuro: Diretório com variáveis do clima futuro\n",
    "    \n",
    "    Returns:\n",
    "        Lista de variáveis em comum\n",
    "    \"\"\"\n",
    "    print(f\"Verificando consistência entre {dir_atual} e {dir_futuro}\")\n",
    "    \n",
    "    arquivos_atual = set(os.path.basename(f) for f in glob.glob(os.path.join(dir_atual, \"*.tif\")))\n",
    "    arquivos_futuro = set(os.path.basename(f) for f in glob.glob(os.path.join(dir_futuro, \"*.tif\")))\n",
    "    \n",
    "    # Verificar arquivos em comum\n",
    "    comuns = arquivos_atual & arquivos_futuro\n",
    "    print(f\"Variáveis em comum: {len(comuns)}\")\n",
    "    \n",
    "    if len(comuns) == 0:\n",
    "        print(\"ERRO: Nenhuma variável em comum encontrada!\")\n",
    "        return []\n",
    "    \n",
    "    # Verificar dimensões\n",
    "    problemas = []\n",
    "    for arquivo in comuns:\n",
    "        try:\n",
    "            with rasterio.open(os.path.join(dir_atual, arquivo)) as src_atual:\n",
    "                with rasterio.open(os.path.join(dir_futuro, arquivo)) as src_futuro:\n",
    "                    if src_atual.shape != src_futuro.shape:\n",
    "                        print(f\"ALERTA: {arquivo} tem dimensões diferentes entre cenários\")\n",
    "                        print(f\"  Atual: {src_atual.shape}, Futuro: {src_futuro.shape}\")\n",
    "                        problemas.append(arquivo)\n",
    "                    if src_atual.crs != src_futuro.crs:\n",
    "                        print(f\"ALERTA: {arquivo} tem CRS diferentes entre cenários\")\n",
    "                        problemas.append(arquivo)\n",
    "        except Exception as e:\n",
    "            print(f\"ERRO ao verificar {arquivo}: {str(e)}\")\n",
    "            problemas.append(arquivo)\n",
    "    \n",
    "    # Remover arquivos problemáticos da lista\n",
    "    comuns_ok = [arq for arq in comuns if arq not in problemas]\n",
    "    \n",
    "    if problemas:\n",
    "        print(f\"ALERTA: {len(problemas)} variáveis com problemas foram removidas da lista\")\n",
    "    \n",
    "    print(f\"Variáveis consistentes: {len(comuns_ok)}\")\n",
    "    return sorted(list(comuns_ok))\n",
    "\n",
    "def criar_metadados(variaveis, arquivo_saida=\"metadados_variaveis.md\"):\n",
    "    \"\"\"\n",
    "    Cria um arquivo de metadados para as variáveis bioclimáticas\n",
    "    \n",
    "    Args:\n",
    "        variaveis: Lista de nomes de arquivos das variáveis\n",
    "        arquivo_saida: Nome do arquivo de saída\n",
    "    \"\"\"\n",
    "    descricoes = {\n",
    "        \"bio1.tif\": \"Temperatura Média Anual\",\n",
    "        \"bio2.tif\": \"Amplitude Média Diurna (média mensal de (temp max - temp min))\",\n",
    "        \"bio3.tif\": \"Isotermalidade (bio2/bio7) (×100)\",\n",
    "        \"bio4.tif\": \"Sazonalidade da Temperatura (desvio padrão ×100)\",\n",
    "        \"bio5.tif\": \"Temperatura Máxima do Mês Mais Quente\",\n",
    "        \"bio6.tif\": \"Temperatura Mínima do Mês Mais Frio\",\n",
    "        \"bio7.tif\": \"Amplitude Térmica Anual (bio5-bio6)\",\n",
    "        \"bio8.tif\": \"Temperatura Média do Trimestre Mais Úmido\",\n",
    "        \"bio9.tif\": \"Temperatura Média do Trimestre Mais Seco\",\n",
    "        \"bio10.tif\": \"Temperatura Média do Trimestre Mais Quente\",\n",
    "        \"bio11.tif\": \"Temperatura Média do Trimestre Mais Frio\",\n",
    "        \"bio12.tif\": \"Precipitação Anual\",\n",
    "        \"bio13.tif\": \"Precipitação do Mês Mais Úmido\",\n",
    "        \"bio14.tif\": \"Precipitação do Mês Mais Seco\",\n",
    "        \"bio15.tif\": \"Sazonalidade da Precipitação (coeficiente de variação)\",\n",
    "        \"bio16.tif\": \"Precipitação do Trimestre Mais Úmido\",\n",
    "        \"bio17.tif\": \"Precipitação do Trimestre Mais Seco\",\n",
    "        \"bio18.tif\": \"Precipitação do Trimestre Mais Quente\",\n",
    "        \"bio19.tif\": \"Precipitação do Trimestre Mais Frio\"\n",
    "    }\n",
    "    \n",
    "    with open(arquivo_saida, \"w\") as f:\n",
    "        f.write(\"# Metadados das Variáveis Bioclimáticas\\n\\n\")\n",
    "        f.write(\"| Arquivo | Descrição | Unidade |\\n\")\n",
    "        f.write(\"|---------|-----------|--------|\\n\")\n",
    "        \n",
    "        for var in sorted(variaveis):\n",
    "            nome_base = os.path.basename(var)\n",
    "            descricao = descricoes.get(nome_base, \"Descrição não disponível\")\n",
    "            unidade = \"°C\" if int(nome_base.replace(\"bio\", \"\").split(\".\")[0]) < 12 else \"mm\"\n",
    "            f.write(f\"| {nome_base} | {descricao} | {unidade} |\\n\")\n",
    "    \n",
    "    print(f\"Metadados criados: {arquivo_saida}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Função principal para processar arquivos bioclimáticos\"\"\"\n",
    "    # Diretórios\n",
    "    dir_downloads = \"downloads\"\n",
    "    dir_clima_atual = \"clima_atual\"\n",
    "    dir_clima_futuro = \"clima_futuro\"\n",
    "    \n",
    "    # Criar diretórios se não existirem\n",
    "    os.makedirs(dir_downloads, exist_ok=True)\n",
    "    os.makedirs(dir_clima_atual, exist_ok=True)\n",
    "    os.makedirs(dir_clima_futuro, exist_ok=True)\n",
    "    \n",
    "    # Perguntar ao usuário o que deseja fazer\n",
    "    print(\"\\n===== PROCESSADOR DE VARIÁVEIS BIOCLIMÁTICAS =====\\n\")\n",
    "    print(\"Escolha uma opção:\")\n",
    "    print(\"1. Extrair variáveis de arquivo .tif multi-banda\")\n",
    "    print(\"2. Padronizar nomes de arquivos existentes\")\n",
    "    print(\"3. Verificar consistência entre clima atual e futuro\")\n",
    "    print(\"4. Criar metadados para as variáveis\")\n",
    "    print(\"5. Executar todo o processo\")\n",
    "    print(\"6. Processar pastas que já contêm arquivos bio*.tif\")\n",
    "    print(\"0. Sair\")\n",
    "    \n",
    "    opcao = input(\"\\nOpção: \")\n",
    "    \n",
    "    if opcao == \"1\":\n",
    "        arquivo_tif = input(\"Caminho para o arquivo .tif multi-banda: \")\n",
    "        diretorio_saida = input(\"Diretório de saída [clima_atual]: \") or \"clima_atual\"\n",
    "        extrair_variaveis_bioclimaticas(arquivo_tif, diretorio_saida)\n",
    "    \n",
    "    elif opcao == \"2\":\n",
    "        diretorio_origem = input(\"Diretório com arquivos originais: \")\n",
    "        diretorio_destino = input(\"Diretório de destino para arquivos padronizados: \")\n",
    "        padronizar_nomes_arquivos(diretorio_origem, diretorio_destino)\n",
    "    \n",
    "    elif opcao == \"3\":\n",
    "        dir_atual = input(\"Diretório com clima atual [clima_atual]: \") or \"clima_atual\"\n",
    "        dir_futuro = input(\"Diretório com clima futuro [clima_futuro]: \") or \"clima_futuro\"\n",
    "        variaveis_comuns = verificar_consistencia(dir_atual, dir_futuro)\n",
    "        \n",
    "        # Salvar lista de variáveis em comum\n",
    "        if variaveis_comuns:\n",
    "            with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "                for var in variaveis_comuns:\n",
    "                    f.write(f\"{var}\\n\")\n",
    "            print(f\"Lista de variáveis salva em variaveis_usadas.txt\")\n",
    "    \n",
    "    elif opcao == \"4\":\n",
    "        dir_variaveis = input(\"Diretório com variáveis [clima_atual]: \") or \"clima_atual\"\n",
    "        variaveis = [os.path.basename(f) for f in glob.glob(os.path.join(dir_variaveis, \"*.tif\"))]\n",
    "        arquivo_saida = input(\"Nome do arquivo de saída [metadados_variaveis.md]: \") or \"metadados_variaveis.md\"\n",
    "        criar_metadados(variaveis, arquivo_saida)\n",
    "    \n",
    "    elif opcao == \"5\":\n",
    "        # Perguntar caminhos dos arquivos\n",
    "        arquivo_atual = input(\"Caminho para o arquivo .tif do clima atual: \")\n",
    "        arquivo_futuro = input(\"Caminho para o arquivo .tif do clima futuro: \")\n",
    "        \n",
    "        # Extrair variáveis\n",
    "        if os.path.exists(arquivo_atual):\n",
    "            if os.path.isdir(arquivo_atual):\n",
    "                print(f\"AVISO: {arquivo_atual} é um diretório, não um arquivo .tif\")\n",
    "            else:\n",
    "                extrair_variaveis_bioclimaticas(arquivo_atual, dir_clima_atual)\n",
    "        else:\n",
    "            print(f\"ERRO: Arquivo {arquivo_atual} não encontrado\")\n",
    "        \n",
    "        if os.path.exists(arquivo_futuro):\n",
    "            if os.path.isdir(arquivo_futuro):\n",
    "                print(f\"AVISO: {arquivo_futuro} é um diretório, não um arquivo .tif\")\n",
    "            else:\n",
    "                extrair_variaveis_bioclimaticas(arquivo_futuro, dir_clima_futuro)\n",
    "        else:\n",
    "            print(f\"ERRO: Arquivo {arquivo_futuro} não encontrado\")\n",
    "        \n",
    "        # Verificar consistência\n",
    "        variaveis_comuns = verificar_consistencia(dir_clima_atual, dir_clima_futuro)\n",
    "        \n",
    "        # Salvar lista de variáveis em comum\n",
    "        if variaveis_comuns:\n",
    "            with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "                for var in variaveis_comuns:\n",
    "                    f.write(f\"{var}\\n\")\n",
    "            print(f\"Lista de variáveis salva em variaveis_usadas.txt\")\n",
    "            \n",
    "            # Criar metadados\n",
    "            criar_metadados(variaveis_comuns)\n",
    "    \n",
    "    elif opcao == \"6\":\n",
    "        print(\"\\nProcessando pastas existentes com arquivos bio*.tif\")\n",
    "        dir_atual = input(\"Diretório com clima atual [clima_atual]: \") or \"clima_atual\"\n",
    "        dir_futuro = input(\"Diretório com clima futuro [clima_futuro]: \") or \"clima_futuro\"\n",
    "        \n",
    "        # Verificar se as pastas existem\n",
    "        if not os.path.isdir(dir_atual):\n",
    "            print(f\"ERRO: Diretório {dir_atual} não encontrado\")\n",
    "            return\n",
    "        if not os.path.isdir(dir_futuro):\n",
    "            print(f\"ERRO: Diretório {dir_futuro} não encontrado\")\n",
    "            return\n",
    "            \n",
    "        # Verificar consistência\n",
    "        variaveis_comuns = verificar_consistencia(dir_atual, dir_futuro)\n",
    "        \n",
    "        # Salvar lista de variáveis em comum\n",
    "        if variaveis_comuns:\n",
    "            with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "                for var in variaveis_comuns:\n",
    "                    f.write(f\"{var}\\n\")\n",
    "            print(f\"Lista de variáveis salva em variaveis_usadas.txt\")\n",
    "            \n",
    "            # Criar metadados\n",
    "            criar_metadados(variaveis_comuns)\n",
    "    \n",
    "    elif opcao == \"0\":\n",
    "        print(\"Saindo...\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Opção inválida!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674a6df",
   "metadata": {},
   "source": [
    "## Ajustar Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc570fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def obter_variaveis_disponiveis():\n",
    "    \"\"\"Identifica todas as variáveis bioclimáticas disponíveis em ambos cenários\"\"\"\n",
    "    cli_atual = set(os.path.basename(f) for f in glob.glob(\"clima_atual/*.tif\"))\n",
    "    cli_futuro = set(os.path.basename(f) for f in glob.glob(\"clima_futuro/clima_futuro2/*.tif\"))\n",
    "    comuns = sorted(list(cli_atual & cli_futuro))\n",
    "    print(f\"✅ Variáveis em comum: {len(comuns)}\")\n",
    "    for var in comuns:\n",
    "        print(f\"  - {var}\")\n",
    "\n",
    "    # NOVO: Verifica se os arquivos futuros estão corretos e tem o mesmo formato\n",
    "    try:\n",
    "        with rasterio.open(os.path.join(\"clima_atual\", comuns[0])) as src_atual:\n",
    "            shape_atual = src_atual.shape\n",
    "        with rasterio.open(os.path.join(\"clima_futuro\", comuns[0])) as src_futuro:\n",
    "            shape_futuro = src_futuro.shape\n",
    "        \n",
    "        if shape_atual != shape_futuro:\n",
    "            print(f\"⚠️ ALERTA: Arquivos atuais ({shape_atual}) e futuros ({shape_futuro}) têm dimensões diferentes!\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erro ao verificar dimensões dos arquivos: {str(e)}\")\n",
    "    \n",
    "    return comuns\n",
    "\n",
    "def stack_rasters(raster_dir, selected_files):\n",
    "    \"\"\"Empilha múltiplos rasters em um único array 3D\"\"\"\n",
    "    files = [os.path.join(raster_dir, f) for f in selected_files]\n",
    "    arrays = []\n",
    "    meta = None\n",
    "    for file in tqdm(files, desc=f\"📚 Empilhando rasters em {raster_dir}\"):\n",
    "        with rasterio.open(file) as src:\n",
    "            if meta is None:\n",
    "                meta = src.meta.copy()\n",
    "            arrays.append(src.read(1))\n",
    "    stacked = np.stack(arrays, axis=-1)\n",
    "    return stacked, meta\n",
    "\n",
    "def extract_values(coords, raster_stack, meta):\n",
    "    \"\"\"Extrai valores de raster para cada coordenada\"\"\"\n",
    "    results = []\n",
    "    for lat, lon in tqdm(coords, desc=\"📌 Extraindo valores\"):\n",
    "        row, col = rasterio.transform.rowcol(meta['transform'], lon, lat)\n",
    "        if 0 <= row < raster_stack.shape[0] and 0 <= col < raster_stack.shape[1]:\n",
    "            results.append(raster_stack[row, col])\n",
    "        else:\n",
    "            results.append([np.nan]*raster_stack.shape[2])\n",
    "    return np.array(results)\n",
    "\n",
    "def generate_pseudo_absences(clima, meta, pres_coords, n_samples, min_dist_km=30):\n",
    "    \"\"\"Gera pontos de pseudo-ausência longe das presenças conhecidas\"\"\"\n",
    "    absences = []\n",
    "    attempts = 0\n",
    "    max_attempts = n_samples * 30  # Aumentado para mais tentativas\n",
    "    \n",
    "    print(f\"🎯 Gerando {n_samples} pseudo-ausências\")\n",
    "    with tqdm(total=n_samples, desc=\"🚫 Gerando pseudo-ausências\") as pbar:\n",
    "        while len(absences) < n_samples and attempts < max_attempts:\n",
    "            # Estratégia para melhor distribuição espacial: dividir em quadrantes\n",
    "            row = np.random.randint(0, clima.shape[0])\n",
    "            col = np.random.randint(0, clima.shape[1])\n",
    "            vals = clima[row, col]\n",
    "            if np.isnan(vals).any():\n",
    "                attempts += 1\n",
    "                continue\n",
    "            lon, lat = rasterio.transform.xy(meta['transform'], row, col)\n",
    "            \n",
    "            # Verifica distância mínima das presenças (agora 30km em vez de 20km)\n",
    "            if all(geodesic((lat, lon), pc).km > min_dist_km for pc in pres_coords):\n",
    "                absences.append(vals)\n",
    "                pbar.update(1)\n",
    "            attempts += 1\n",
    "    \n",
    "    return np.array(absences)\n",
    "\n",
    "def ajustar_modelo():\n",
    "    print(\"🔄 Iniciando ajuste do modelo para reduzir overfitting...\")\n",
    "    \n",
    "    # Obter variáveis disponíveis\n",
    "    variaveis = obter_variaveis_disponiveis()\n",
    "    \n",
    "    if len(variaveis) <= 2:\n",
    "        print(\"⚠️ Apenas 2 variáveis bioclimáticas disponíveis. Para melhor desempenho, adicione mais variáveis.\")\n",
    "    \n",
    "    # Ler ocorrências\n",
    "    print(\"📊 Lendo dados de ocorrência...\")\n",
    "    df = pd.read_csv(\"ocorrencias.csv\")\n",
    "    coords = list(zip(df[\"latitude\"], df[\"longitude\"]))\n",
    "    print(f\"✅ Presenças: {len(coords)}\")\n",
    "    \n",
    "    # Empilhar rasters\n",
    "    print(\"📚 Empilhando rasters...\")\n",
    "    clima_atual, meta_atual = stack_rasters(\"clima_atual\", variaveis)\n",
    "    print(f\"✅ Clima atual empilhado: {clima_atual.shape}\")\n",
    "    \n",
    "    # Extrair valores para presenças\n",
    "    presenças = extract_values(coords, clima_atual, meta_atual)\n",
    "    \n",
    "    # Remover presenças com NaN\n",
    "    nan_mask = np.isnan(presenças).any(axis=1)\n",
    "    if nan_mask.any():\n",
    "        print(f\"⚠️ Removendo {nan_mask.sum()} presenças com valores NaN\")\n",
    "        presenças = presenças[~nan_mask]\n",
    "        presenca_coords = [coord for i, coord in enumerate(coords) if not nan_mask[i]]\n",
    "    else:\n",
    "        presenca_coords = coords\n",
    "    \n",
    "    # Gerar pseudo-ausências\n",
    "    n_ausencias = len(presenças)\n",
    "    ausencias = generate_pseudo_absences(clima_atual, meta_atual, presenca_coords, n_ausencias, min_dist_km=30)\n",
    "    \n",
    "    # Preparar dados para treinamento\n",
    "    X = np.vstack((presenças, ausencias))\n",
    "    y = np.array([1]*len(presenças) + [0]*len(ausencias))\n",
    "    \n",
    "    # Normalizar dados\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Dividir em treino/teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2)\n",
    "    \n",
    "    # Treinar modelo com parâmetros para prevenir overfitting\n",
    "    print(\"🔧 Treinando modelo com parâmetros para reduzir overfitting...\")\n",
    "    \n",
    "    # Parâmetros mais conservadores para evitar overfitting\n",
    "    # - Aumentando min_samples_leaf ainda mais\n",
    "    # - Limitando max_depth para evitar árvores muito profundas\n",
    "    # - Reduzindo número de árvores para evitar memorização\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=50,          # Menos árvores (era 100)\n",
    "        min_samples_leaf=30,      # Muito maior (era 10)\n",
    "        max_depth=10,             # Mais limitado (era 15)\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    test_acc = rf.score(X_test, y_test)\n",
    "    print(f\"✅ Acurácia no teste: {test_acc:.3f}\")\n",
    "    \n",
    "    # Salvar modelo\n",
    "    print(\"💾 Salvando modelo e scaler...\")\n",
    "    joblib.dump(rf, \"modelo_ajustado.pkl\")\n",
    "    joblib.dump(scaler, \"scaler_ajustado.pkl\")\n",
    "    joblib.dump(variaveis, \"variaveis_usadas.pkl\")\n",
    "    \n",
    "    # Salvar lista de variáveis\n",
    "    with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "        for var in variaveis:\n",
    "            f.write(f\"{var}\\n\")\n",
    "    \n",
    "    print(\"✅ Modelo ajustado! Para gerar os novos mapas, execute:\")\n",
    "    print(\"1. python gerar_mapas_ajustados.py\")\n",
    "    print(\"2. python mascarar_brasil.py\")\n",
    "    print(\"3. python visualizar_mapas.py\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ajustar_modelo() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ab8c9",
   "metadata": {},
   "source": [
    "## Gerar Mapas Ajustados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def carregar_arquivos():\n",
    "    \"\"\"Carrega modelo, scaler e lista de variáveis\"\"\"\n",
    "    if not os.path.exists(\"modelo_ajustado.pkl\"):\n",
    "        print(\"❌ Modelo ajustado não encontrado. Execute ajustar_modelo.py primeiro.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    modelo = joblib.load(\"modelo_ajustado.pkl\")\n",
    "    scaler = joblib.load(\"scaler_ajustado.pkl\")\n",
    "    \n",
    "    if os.path.exists(\"variaveis_usadas.pkl\"):\n",
    "        variaveis = joblib.load(\"variaveis_usadas.pkl\")\n",
    "    else:\n",
    "        # Fallback para arquivo de texto\n",
    "        with open(\"variaveis_usadas.txt\", \"r\") as f:\n",
    "            variaveis = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return modelo, scaler, variaveis\n",
    "\n",
    "def stack_rasters(raster_dir, selected_files):\n",
    "    \"\"\"Empilha múltiplos rasters em um único array 3D\"\"\"\n",
    "    files = [os.path.join(raster_dir, f) for f in selected_files]\n",
    "    arrays = []\n",
    "    meta = None\n",
    "    shape_ref = None\n",
    "    \n",
    "    # Primeiro, verificar as dimensões de todos os arquivos\n",
    "    print(f\"🔍 Verificando consistência dos arquivos em {raster_dir}...\")\n",
    "    for file in files:\n",
    "        with rasterio.open(file) as src:\n",
    "            if shape_ref is None:\n",
    "                shape_ref = src.shape\n",
    "                print(f\"  📏 Dimensões esperadas: {shape_ref}\")\n",
    "            elif src.shape != shape_ref:\n",
    "                print(f\"  ⚠️ ALERTA: {os.path.basename(file)} tem dimensões diferentes: {src.shape}\")\n",
    "                return None, None\n",
    "    \n",
    "    # Se passou na verificação, empilhar os rasters\n",
    "    for file in tqdm(files, desc=f\"📚 Empilhando rasters em {raster_dir}\"):\n",
    "        with rasterio.open(file) as src:\n",
    "            if meta is None:\n",
    "                meta = src.meta.copy()\n",
    "            data = src.read(1)\n",
    "            # Verificar se há valores válidos\n",
    "            if np.all(np.isnan(data)):\n",
    "                print(f\"  ⚠️ ALERTA: {os.path.basename(file)} contém apenas valores NaN\")\n",
    "            arrays.append(data)\n",
    "    \n",
    "    stacked = np.stack(arrays, axis=-1)\n",
    "    return stacked, meta\n",
    "\n",
    "def predizer_mapa(modelo, scaler, clima, meta, nome_saida):\n",
    "    \"\"\"Prediz probabilidade de ocorrência para cada pixel\"\"\"\n",
    "    print(f\"🗺️ Projetando distribuição para: {nome_saida}\")\n",
    "    \n",
    "    # Preparar dados\n",
    "    shape_original = clima.shape[:2]\n",
    "    clima_reshaped = clima.reshape(-1, clima.shape[2])\n",
    "    \n",
    "    # Identificar valores válidos (não-NaN)\n",
    "    valid_mask = ~np.isnan(clima_reshaped).any(axis=1)\n",
    "    valid_indices = np.where(valid_mask)[0]\n",
    "    \n",
    "    # Inicializar mapa de predição com NaN\n",
    "    pred_map = np.full(clima_reshaped.shape[0], np.nan)\n",
    "    \n",
    "    # Aplicar scaler e prever apenas para pixels válidos\n",
    "    if len(valid_indices) > 0:\n",
    "        print(f\"✅ Predizendo {len(valid_indices)} pixels válidos...\")\n",
    "        valid_data = clima_reshaped[valid_indices]\n",
    "        valid_data_scaled = scaler.transform(valid_data)\n",
    "        \n",
    "        # Processar em lotes para economizar memória\n",
    "        batch_size = 100000\n",
    "        n_batches = (len(valid_indices) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in tqdm(range(n_batches), desc=\"🔍 Processando em lotes\"):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(valid_indices))\n",
    "            batch_data = valid_data_scaled[start_idx:end_idx]\n",
    "            batch_preds = modelo.predict_proba(batch_data)[:, 1]\n",
    "            pred_map[valid_indices[start_idx:end_idx]] = batch_preds\n",
    "    \n",
    "    # Redimensionar para formato original\n",
    "    pred_map = pred_map.reshape(shape_original)\n",
    "    \n",
    "    # Salvar resultado\n",
    "    print(f\"💾 Salvando mapa em: {nome_saida}\")\n",
    "    with rasterio.open(nome_saida, \"w\", **meta) as dst:\n",
    "        dst.write(pred_map, 1)\n",
    "    \n",
    "    return pred_map\n",
    "\n",
    "def gerar_mapas():\n",
    "    # Carregar modelo e parâmetros\n",
    "    print(\"🔍 Carregando modelo ajustado...\")\n",
    "    modelo, scaler, variaveis = carregar_arquivos()\n",
    "    \n",
    "    if modelo is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Modelo carregado com sucesso. Usando {len(variaveis)} variáveis bioclimáticas:\")\n",
    "    for var in variaveis:\n",
    "        print(f\"  - {var}\")\n",
    "    \n",
    "    # Empilhar clima atual\n",
    "    print(\"\\n📚 Empilhando clima atual...\")\n",
    "    clima_atual, meta_atual = stack_rasters(\"clima_atual\", variaveis)\n",
    "    if clima_atual is None:\n",
    "        print(\"❌ Erro ao empilhar clima atual. Verifique as dimensões dos arquivos.\")\n",
    "        return\n",
    "    print(f\"✅ Clima atual empilhado: {clima_atual.shape}\")\n",
    "    \n",
    "    # Escolher qual conjunto de dados futuros usar\n",
    "    print(\"\\n🔄 Escolha o conjunto de dados futuros:\")\n",
    "    print(\"1. clima_futuro2 (variáveis do bio1.tif)\")\n",
    "    print(\"2. clima_futuro3 (variáveis do bio2.tif)\")\n",
    "    opcao = input(\"Opção (1 ou 2): \").strip()\n",
    "    \n",
    "    if opcao == \"1\":\n",
    "        dir_futuro = \"clima_futuro/clima_futuro2\"\n",
    "        sufixo = \"futuro2\"\n",
    "    elif opcao == \"2\":\n",
    "        dir_futuro = \"clima_futuro/clima_futuro3\"\n",
    "        sufixo = \"futuro3\"\n",
    "    else:\n",
    "        print(\"❌ Opção inválida!\")\n",
    "        return\n",
    "    \n",
    "    # Empilhar clima futuro\n",
    "    print(f\"\\n📚 Empilhando clima futuro de {dir_futuro}...\")\n",
    "    clima_futuro, meta_futuro = stack_rasters(dir_futuro, variaveis)\n",
    "    if clima_futuro is None:\n",
    "        print(\"❌ Erro ao empilhar clima futuro. Verifique as dimensões dos arquivos.\")\n",
    "        return\n",
    "    print(f\"✅ Clima futuro empilhado: {clima_futuro.shape}\")\n",
    "    \n",
    "    # Verificar se as dimensões são compatíveis\n",
    "    if clima_atual.shape != clima_futuro.shape:\n",
    "        print(f\"❌ Erro: Dimensões incompatíveis entre clima atual ({clima_atual.shape}) e futuro ({clima_futuro.shape})\")\n",
    "        return\n",
    "    \n",
    "    # Predizer mapas\n",
    "    mapa_atual = predizer_mapa(modelo, scaler, clima_atual, meta_atual, f\"mapa_predito_atual_{sufixo}.tif\")\n",
    "    mapa_futuro = predizer_mapa(modelo, scaler, clima_futuro, meta_futuro, f\"mapa_predito_{sufixo}.tif\")\n",
    "    \n",
    "    # Calcular mudança\n",
    "    if mapa_atual is not None and mapa_futuro is not None:\n",
    "        print(\"📊 Calculando mapa de mudança (futuro - atual)...\")\n",
    "        mapa_mudanca = mapa_futuro - mapa_atual\n",
    "        with rasterio.open(f\"mapa_mudanca_{sufixo}.tif\", \"w\", **meta_atual) as dst:\n",
    "            dst.write(mapa_mudanca, 1)\n",
    "    \n",
    "    print(\"\\n✅ Mapas gerados com sucesso! Para continuar o fluxo:\")\n",
    "    print(f\"1. Execute: python mascarar_brasil.py (usando os mapas com sufixo _{sufixo})\")\n",
    "    print(\"2. Execute: python visualizar_mapas.py\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gerar_mapas() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fe838",
   "metadata": {},
   "source": [
    "## Mascarar Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d409ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def aplicar_mascara(mapa_path, shapefile_brasil, saida_path):\n",
    "    print(f\"🗺️ Aplicando máscara ao arquivo: {mapa_path}\")\n",
    "\n",
    "    # Verifica se os arquivos existem\n",
    "    if not os.path.exists(mapa_path):\n",
    "        print(f\"❌ Arquivo de mapa não encontrado: {mapa_path}\")\n",
    "        return False\n",
    "    if not os.path.exists(shapefile_brasil):\n",
    "        print(f\"❌ Shapefile não encontrado: {shapefile_brasil}\")\n",
    "        return False\n",
    "\n",
    "    # Lê o shapefile do Brasil\n",
    "    try:\n",
    "        print(f\"📂 Lendo shapefile: {shapefile_brasil}\")\n",
    "        brasil = gpd.read_file(shapefile_brasil)\n",
    "        geoms = brasil.geometry.values\n",
    "        print(f\"✅ Shapefile carregado com {len(brasil)} feições\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao ler o shapefile: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # Abre o raster de entrada\n",
    "    try:\n",
    "        print(f\"📊 Lendo raster: {mapa_path}\")\n",
    "        with rasterio.open(mapa_path) as src:\n",
    "            print(f\"📏 Dimensões do raster: {src.width}x{src.height}\")\n",
    "            print(\"🔍 Aplicando máscara...\")\n",
    "            out_image, out_transform = mask(src, geoms, crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao processar o raster: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # Atualiza os metadados\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"nodata\": src.nodata or -9999\n",
    "    })\n",
    "\n",
    "    # Salva o novo arquivo mascarado\n",
    "    try:\n",
    "        with rasterio.open(saida_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "        print(f\"✅ Mapa salvo com máscara: {saida_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar o resultado: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def detectar_mapas_gerados():\n",
    "    \"\"\"Detecta automaticamente os mapas gerados pelo gerar_mapas_ajustados.py\"\"\"\n",
    "    padroes = [\n",
    "        \"mapa_predito_atual_*.tif\",\n",
    "        \"mapa_predito_futuro*.tif\", \n",
    "        \"mapa_mudanca_*.tif\"\n",
    "    ]\n",
    "    \n",
    "    arquivos_encontrados = []\n",
    "    for padrao in padroes:\n",
    "        arquivos = glob.glob(padrao)\n",
    "        arquivos_encontrados.extend(arquivos)\n",
    "    \n",
    "    # Remove duplicatas e ordena\n",
    "    return sorted(list(set(arquivos_encontrados)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Caminho para o shapefile\n",
    "    shapefile_brasil = os.path.join(\"BR_UF_2024\", \"BR_UF_2024.shp\")\n",
    "    \n",
    "    # Detectar mapas gerados automaticamente\n",
    "    arquivos = detectar_mapas_gerados()\n",
    "    \n",
    "    if not arquivos:\n",
    "        print(\"❌ Nenhum mapa gerado encontrado!\")\n",
    "        print(\"Execute primeiro: python gerar_mapas_ajustados.py\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"📋 Mapas encontrados para processar:\")\n",
    "    for arquivo in arquivos:\n",
    "        print(f\"  - {arquivo}\")\n",
    "    \n",
    "    # Processa cada arquivo\n",
    "    sucessos = 0\n",
    "    for arquivo in tqdm(arquivos, desc=\"🗺️ Processando mapas\"):\n",
    "        # Criar nome de saída\n",
    "        nome_base = os.path.splitext(arquivo)[0]\n",
    "        saida = f\"{nome_base}_brasil.tif\"\n",
    "        \n",
    "        if aplicar_mascara(arquivo, shapefile_brasil, saida):\n",
    "            sucessos += 1\n",
    "        print()  # Linha em branco para separar\n",
    "    \n",
    "    # Resumo\n",
    "    print(f\"✅ Concluído: {sucessos}/{len(arquivos)} mapas processados com sucesso\")\n",
    "    \n",
    "    if sucessos > 0:\n",
    "        print(\"\\n📂 Arquivos gerados com máscara do Brasil:\")\n",
    "        arquivos_brasil = glob.glob(\"*_brasil.tif\")\n",
    "        for arquivo in sorted(arquivos_brasil):\n",
    "            print(f\"  ✅ {arquivo}\")\n",
    "        \n",
    "        print(\"\\n🎯 Próximos passos:\")\n",
    "        print(\"1. Execute: python visualizar_mapas.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9897401",
   "metadata": {},
   "source": [
    "## Visualizar Mapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd251840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def detectar_mapas_brasil():\n",
    "    \"\"\"Detecta automaticamente os mapas mascarados do Brasil\"\"\"\n",
    "    mapas_encontrados = {}\n",
    "    \n",
    "    # Procurar mapas de distribuição atual\n",
    "    atual_files = glob.glob(\"mapa_predito_atual_*_brasil.tif\")\n",
    "    if atual_files:\n",
    "        mapas_encontrados[\"atual\"] = atual_files[0]\n",
    "    \n",
    "    # Procurar mapas de distribuição futura\n",
    "    futuro_files = glob.glob(\"mapa_predito_futuro*_brasil.tif\")\n",
    "    if futuro_files:\n",
    "        mapas_encontrados[\"futuro\"] = futuro_files[0]\n",
    "    \n",
    "    # Procurar mapas de mudança\n",
    "    mudanca_files = glob.glob(\"mapa_mudanca_*_brasil.tif\")\n",
    "    if mudanca_files:\n",
    "        mapas_encontrados[\"mudanca\"] = mudanca_files[0]\n",
    "    \n",
    "    return mapas_encontrados\n",
    "\n",
    "def visualizar_mapa(tif_path, titulo, salvar=True, escala_padronizada=True):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(1).astype(float)\n",
    "\n",
    "        # Trata valores nodata\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = np.nan\n",
    "\n",
    "        # Obtém valores mínimo e máximo reais para estatísticas\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        if len(valid_data) == 0:\n",
    "            print(f\"❌ Nenhum dado válido encontrado em {titulo}\")\n",
    "            return\n",
    "            \n",
    "        v_min_real = np.nanmin(valid_data)\n",
    "        v_max_real = np.nanmax(valid_data)\n",
    "        \n",
    "        # Calcula estatísticas básicas\n",
    "        mean = np.nanmean(valid_data)\n",
    "        std = np.nanstd(valid_data)\n",
    "        \n",
    "        print(f\"📊 Estatísticas para {titulo}:\")\n",
    "        print(f\"   - Min: {v_min_real:.4f}, Max: {v_max_real:.4f}, Média: {mean:.4f}, Desvio: {std:.4f}\")\n",
    "        \n",
    "        # Define escala de visualização\n",
    "        if escala_padronizada:\n",
    "            if \"mudança\" in titulo.lower() or \"mudanca\" in titulo.lower():\n",
    "                # Para mapas de mudança: escala simétrica baseada no máximo absoluto global\n",
    "                abs_max = max(abs(v_min_real), abs(v_max_real))\n",
    "                # Usar uma escala padrão de -0.8 a +0.8 para mudanças\n",
    "                v_min, v_max = -0.8, 0.8\n",
    "                cmap = plt.cm.RdBu_r  # Vermelho = perda, Azul = ganho\n",
    "                label = 'Mudança na Probabilidade'\n",
    "                print(f\"   📏 Escala padronizada para mudança: {v_min} a {v_max}\")\n",
    "            else:\n",
    "                # Para mapas de probabilidade: escala padronizada 0-1\n",
    "                v_min, v_max = 0.0, 1.0\n",
    "                cmap = plt.cm.viridis\n",
    "                label = 'Probabilidade de Adequabilidade'\n",
    "                print(f\"   📏 Escala padronizada para probabilidade: {v_min} a {v_max}\")\n",
    "        else:\n",
    "            # Escala dinâmica baseada nos dados\n",
    "            v_min, v_max = v_min_real, v_max_real\n",
    "            if \"mudança\" in titulo.lower() or \"mudanca\" in titulo.lower():\n",
    "                cmap = plt.cm.RdBu_r\n",
    "                label = 'Mudança na Probabilidade'\n",
    "            else:\n",
    "                cmap = plt.cm.viridis\n",
    "                label = 'Probabilidade de Adequabilidade'\n",
    "            print(f\"   📏 Escala dinâmica: {v_min:.4f} a {v_max:.4f}\")\n",
    "        \n",
    "        # Configura visualização\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Cria o mapa\n",
    "        im = plt.imshow(data, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "        \n",
    "        # Adiciona título e legenda\n",
    "        plt.title(titulo, fontsize=16, pad=20)\n",
    "        plt.axis('off')\n",
    "        cbar = plt.colorbar(im, label=label, shrink=0.7)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        # Adiciona informações sobre valores reais e escala\n",
    "        info_text = f\"Valores reais: {v_min_real:.4f} a {v_max_real:.4f}\\nMédia: {mean:.4f} ± {std:.4f}\"\n",
    "        if escala_padronizada:\n",
    "            info_text += f\"\\nEscala padronizada: {v_min} a {v_max}\"\n",
    "        \n",
    "        plt.annotate(info_text, \n",
    "                     xy=(0.02, 0.02), xycoords='figure fraction', \n",
    "                     fontsize=11, color='black', backgroundcolor='white',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva o mapa em alta resolução para o trabalho acadêmico\n",
    "        if salvar:\n",
    "            nome_arquivo = f\"{titulo.replace(' ', '_').replace('(', '').replace(')', '')}.png\"\n",
    "            plt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\n",
    "            print(f\"💾 Mapa salvo como: {nome_arquivo}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def visualizar_mapa_diferenca(atual_path, futuro_path, escala_padronizada=True):\n",
    "    \"\"\"Cria um mapa de diferença entre distribuição futura e atual\"\"\"\n",
    "    \n",
    "    if not os.path.exists(atual_path) or not os.path.exists(futuro_path):\n",
    "        print(\"❌ Arquivos de mapa não encontrados para calcular diferença\")\n",
    "        return\n",
    "    \n",
    "    with rasterio.open(atual_path) as src_atual, rasterio.open(futuro_path) as src_futuro:\n",
    "        data_atual = src_atual.read(1).astype(float)\n",
    "        data_futuro = src_futuro.read(1).astype(float)\n",
    "        \n",
    "        # Trata valores nodata\n",
    "        if src_atual.nodata is not None:\n",
    "            data_atual[data_atual == src_atual.nodata] = np.nan\n",
    "        if src_futuro.nodata is not None:\n",
    "            data_futuro[data_futuro == src_futuro.nodata] = np.nan\n",
    "        \n",
    "        # Calcula diferença\n",
    "        data_diff = data_futuro - data_atual\n",
    "        \n",
    "        # Configurar visualização\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Paleta divergente para mudanças (vermelho = perda, azul = ganho)\n",
    "        cmap = plt.cm.RdBu_r\n",
    "        \n",
    "        # Determinar limite para visualização\n",
    "        valid_diff = data_diff[~np.isnan(data_diff)]\n",
    "        if len(valid_diff) == 0:\n",
    "            print(\"❌ Nenhum dado válido para calcular diferença\")\n",
    "            return\n",
    "        \n",
    "        v_min_real = np.nanmin(data_diff)\n",
    "        v_max_real = np.nanmax(data_diff)\n",
    "        \n",
    "        if escala_padronizada:\n",
    "            # Escala padronizada para mudanças\n",
    "            v_min, v_max = -0.8, 0.8\n",
    "        else:\n",
    "            # Escala dinâmica simétrica\n",
    "            abs_max = max(abs(v_min_real), abs(v_max_real))\n",
    "            v_min, v_max = -abs_max, abs_max\n",
    "        \n",
    "        im = plt.imshow(data_diff, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "        \n",
    "        plt.title(\"Mudança na Distribuição (Futuro - Atual)\", fontsize=16, pad=20)\n",
    "        plt.axis('off')\n",
    "        cbar = plt.colorbar(im, label='Mudança na Probabilidade', shrink=0.7)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        # Calcular estatísticas da diferença\n",
    "        mean_diff = np.nanmean(data_diff)\n",
    "        perc_loss = np.sum(data_diff < -0.1) / np.sum(~np.isnan(data_diff)) * 100\n",
    "        perc_gain = np.sum(data_diff > 0.1) / np.sum(~np.isnan(data_diff)) * 100\n",
    "        \n",
    "        # Adiciona informações sobre valores\n",
    "        info_text = (f\"Valores reais: {v_min_real:.4f} a {v_max_real:.4f}\\n\"\n",
    "                     f\"Média da mudança: {mean_diff:.4f}\\n\"\n",
    "                     f\"Área com perda (< -0.1): {perc_loss:.1f}%\\n\"\n",
    "                     f\"Área com ganho (> 0.1): {perc_gain:.1f}%\")\n",
    "        \n",
    "        if escala_padronizada:\n",
    "            info_text += f\"\\nEscala padronizada: {v_min} a {v_max}\"\n",
    "        \n",
    "        plt.annotate(info_text, xy=(0.02, 0.02), xycoords='figure fraction', \n",
    "                     fontsize=11, color='black', backgroundcolor='white',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva o mapa\n",
    "        plt.savefig(\"Mudanca_na_Distribuicao.png\", dpi=300, bbox_inches='tight')\n",
    "        print(f\"💾 Mapa de mudança salvo como: Mudanca_na_Distribuicao.png\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Detectar mapas automaticamente\n",
    "    mapas = detectar_mapas_brasil()\n",
    "    \n",
    "    if not mapas:\n",
    "        print(\"❌ Nenhum mapa mascarado encontrado!\")\n",
    "        print(\"Execute primeiro:\")\n",
    "        print(\"1. python gerar_mapas_ajustados.py\")\n",
    "        print(\"2. python mascarar_brasil.py\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"📂 Mapas detectados:\")\n",
    "    for tipo, arquivo in mapas.items():\n",
    "        print(f\"  - {tipo}: {arquivo}\")\n",
    "    \n",
    "    # Perguntar sobre padronização\n",
    "    print(\"\\n🎨 Escolha o tipo de escala para visualização:\")\n",
    "    print(\"1. Escala padronizada (0-1 para probabilidades, -0.8 a +0.8 para mudanças)\")\n",
    "    print(\"2. Escala dinâmica (baseada nos valores dos dados)\")\n",
    "    opcao_escala = input(\"Opção (1 ou 2) [padrão=1]: \").strip() or \"1\"\n",
    "    \n",
    "    escala_padronizada = opcao_escala == \"1\"\n",
    "    \n",
    "    if escala_padronizada:\n",
    "        print(\"✅ Usando escalas padronizadas para comparação científica\")\n",
    "    else:\n",
    "        print(\"✅ Usando escalas dinâmicas para visualização detalhada\")\n",
    "    \n",
    "    # Visualizar mapas de distribuição\n",
    "    if \"atual\" in mapas:\n",
    "        print(f\"\\n📍 Exibindo: Distribuição Atual\")\n",
    "        # Extrair sufixo do arquivo para identificar o cenário\n",
    "        nome_arquivo = os.path.basename(mapas[\"atual\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cenário futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cenário futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"atual\"], f\"Distribuição Atual{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    if \"futuro\" in mapas:\n",
    "        print(f\"\\n📍 Exibindo: Distribuição Futura\")\n",
    "        # Extrair sufixo do arquivo para identificar o cenário\n",
    "        nome_arquivo = os.path.basename(mapas[\"futuro\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cenário futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cenário futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"futuro\"], f\"Distribuição Futura{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    # Visualizar mapa de mudança se disponível\n",
    "    if \"mudanca\" in mapas:\n",
    "        print(f\"\\n📍 Exibindo: Mapa de Mudança\")\n",
    "        nome_arquivo = os.path.basename(mapas[\"mudanca\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cenário futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cenário futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"mudanca\"], f\"Mudança na Distribuição{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    # Se temos atual e futuro, calcular diferença manualmente se não existe mapa de mudança\n",
    "    elif \"atual\" in mapas and \"futuro\" in mapas:\n",
    "        print(f\"\\n📍 Calculando mapa de diferença entre distribuição futura e atual\")\n",
    "        visualizar_mapa_diferenca(mapas[\"atual\"], mapas[\"futuro\"], escala_padronizada=escala_padronizada)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
