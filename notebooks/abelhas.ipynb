{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb194a5",
   "metadata": {},
   "source": [
    "## Algoritmo Random Forest\n",
    "- Previs√£o do posicionamento da Abelha Trigona Spinipes no per√≠odo de 2021-2040, 2041-2060, 2061-80 e 2081-2100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5ccfb",
   "metadata": {},
   "source": [
    "### Configura√ß√£o de Ambiente \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8679c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar depend√™ncias necess√°rias\n",
    "# pip install pandas geopandas rasterio scikit-learn matplotlib streamlit folium streamlit-folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72de8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente configurado e caminhos definidos automaticamente com pathlib!\n",
      "Pasta raiz do projeto encontrada: c:\\icev\\extensao\\abelhas_extensao\n",
      "Caminho do arquivo de ocorr√™ncias: c:\\icev\\extensao\\abelhas_extensao\\data\\ocorrencias.csv\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas (adicionando pathlib)\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path  # <<< IMPORTAMOS A BIBLIOTECA PATHLIB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Ignorar avisos para uma sa√≠da mais limpa\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- DEFINI√á√ÉO AUTOM√ÅTICA DOS CAMINHOS ---\n",
    "# Esta linha m√°gica encontra o caminho da pasta do projeto automaticamente!\n",
    "# Path.cwd() pega o diret√≥rio atual (.../abelhas_extensao/notebooks)\n",
    "# .parent sobe um n√≠vel (.../abelhas_extensao)\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "# Definir os caminhos completos usando o operador / do pathlib\n",
    "OCORRENCIAS_PATH = BASE_DIR / 'data' / 'ocorrencias.csv'\n",
    "CLIMA_ATUAL_PATH = BASE_DIR / 'data' / 'clima_atual'\n",
    "BRASIL_SHAPE_PATH = BASE_DIR / 'data' / 'BR_UF_2024'\n",
    "PASTA_PREVISOES = BASE_DIR / 'data' / 'previsoes_futuras'\n",
    "\n",
    "# Criar a pasta para salvar as previs√µes, se ela n√£o existir\n",
    "PASTA_PREVISOES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Ambiente configurado e caminhos definidos automaticamente com pathlib!\")\n",
    "print(f\"Pasta raiz do projeto encontrada: {BASE_DIR}\")\n",
    "print(f\"Caminho do arquivo de ocorr√™ncias: {OCORRENCIAS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674a6df",
   "metadata": {},
   "source": [
    "### Tratamento e Carregamento dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd89c36",
   "metadata": {},
   "source": [
    "#### Carregar Dados de Ocorr√™ncia e Mapa do Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fc570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar o arquivo 'ocorrencias.csv'...\n",
      "‚ùå Erro: As colunas 'decimalLatitude' ou 'decimalLongitude' n√£o foram encontradas no arquivo.\n",
      "Verifique os nomes das colunas no cabe√ßalho do seu CSV.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ocorrencias_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Ocorreu um erro inesperado ao carregar o arquivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Converter o DataFrame para um GeoDataFrame\u001b[39;00m\n\u001b[0;32m     29\u001b[0m gdf_ocorrencias \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mocorrencias_df\u001b[49m,\n\u001b[0;32m     31\u001b[0m     geometry\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(ocorrencias_df\u001b[38;5;241m.\u001b[39mdecimalLongitude, ocorrencias_df\u001b[38;5;241m.\u001b[39mdecimalLatitude),\n\u001b[0;32m     32\u001b[0m     crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Carregar o mapa do Brasil (shapefile)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m shapefile_brasil \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BRASIL_SHAPE_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ocorrencias_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Carregar dados de ocorr√™ncia de forma robusta (vers√£o corrigida)\n",
    "try:\n",
    "    print(\"Tentando carregar o arquivo 'ocorrencias.csv'...\")\n",
    "    ocorrencias_df_full = pd.read_csv(\n",
    "        OCORRENCIAS_PATH,\n",
    "        comment='#',\n",
    "        on_bad_lines='skip',\n",
    "        low_memory=False,\n",
    "        skipinitialspace=True,  # <<< ADICIONE ESTE PAR√ÇMETRO\n",
    "        encoding='utf-8-sig'    # <<< ADICIONE ESTE PAR√ÇMETRO TAMB√âM\n",
    "    )\n",
    "    \n",
    "    # Agora, selecionamos apenas as colunas que nos interessamos e removemos valores nulos\n",
    "    ocorrencias_df = ocorrencias_df_full[['decimalLatitude', 'decimalLongitude']].dropna()\n",
    "    \n",
    "    print(\"‚úÖ Arquivo carregado com sucesso!\")\n",
    "    print(f\"Total de pontos de ocorr√™ncia carregados: {len(ocorrencias_df)}\")\n",
    "    print(ocorrencias_df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erro: Arquivo n√£o encontrado em '{OCORRENCIAS_PATH}'. Verifique se o caminho est√° correto.\")\n",
    "except KeyError:\n",
    "    print(\"‚ùå Erro: As colunas 'decimalLatitude' ou 'decimalLongitude' n√£o foram encontradas no arquivo.\")\n",
    "    print(\"Verifique os nomes das colunas no cabe√ßalho do seu CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ocorreu um erro inesperado ao carregar o arquivo: {e}\")\n",
    "\n",
    "# Converter o DataFrame para um GeoDataFrame\n",
    "gdf_ocorrencias = gpd.GeoDataFrame(\n",
    "    ocorrencias_df,\n",
    "    geometry=gpd.points_from_xy(ocorrencias_df.decimalLongitude, ocorrencias_df.decimalLatitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Carregar o mapa do Brasil (shapefile)\n",
    "shapefile_brasil = glob.glob(os.path.join(BRASIL_SHAPE_PATH, \"*.shp\"))[0]\n",
    "brasil_gdf = gpd.read_file(shapefile_brasil)\n",
    "\n",
    "# Unir todos os estados em um √∫nico pol√≠gono do Brasil\n",
    "brasil_poligono = brasil_gdf.unary_union\n",
    "\n",
    "print(\"\\nMapa do Brasil e pontos de ocorr√™ncia carregados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484058bf",
   "metadata": {},
   "source": [
    "#### Carregar e empilhar Dados Clim√°ticos Atuais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rasters clim√°ticos atuais empilhados em: c:\\icev\\extensao\\abelhas_extensao\\data\\clima_atual\\clima_atual_stack.tif\n"
     ]
    }
   ],
   "source": [
    "# Listar todos os arquivos .tif de clima atual, em ordem alfab√©tica\n",
    "clima_files = sorted(glob.glob(os.path.join(CLIMA_ATUAL_PATH, \"*.tif\")))\n",
    "\n",
    "# Abrir o primeiro arquivo para obter metadados\n",
    "with rasterio.open(clima_files[0]) as src:\n",
    "    meta = src.meta\n",
    "\n",
    "# Atualizar os metadados para o novo raster empilhado (agora com 19 bandas)\n",
    "meta.update(count=len(clima_files))\n",
    "\n",
    "# Criar o caminho para o arquivo empilhado\n",
    "stack_path = os.path.join(CLIMA_ATUAL_PATH, \"clima_atual_stack.tif\")\n",
    "\n",
    "# Empilhar os rasters em um √∫nico arquivo\n",
    "with rasterio.open(stack_path, 'w', **meta) as dst:\n",
    "    for i, file in enumerate(clima_files, 1):\n",
    "        with rasterio.open(file) as src:\n",
    "            dst.write(src.read(1), i)\n",
    "\n",
    "print(f\"Rasters clim√°ticos atuais empilhados em: {stack_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd1482",
   "metadata": {},
   "source": [
    "#### Gerar Dados de Pseudo-Aus√™ncia\n",
    "- Geramos pontos de pseudo-aus√™ncia em √°reas aleat√≥rias, mas longe dos pontos de presen√ßa, para treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3d21c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_ocorrencias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# N√∫mero de pontos de pseudo-aus√™ncia\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m num_pseudo_ausencias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mgdf_ocorrencias\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Criar uma \"zona de exclus√£o\" ao redor dos pontos de presen√ßa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m buffer_presenca \u001b[38;5;241m=\u001b[39m gdf_ocorrencias\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbuffer(\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39munary_union\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gdf_ocorrencias' is not defined"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# N√∫mero de pontos de pseudo-aus√™ncia\n",
    "num_pseudo_ausencias = len(gdf_ocorrencias) * 2\n",
    "\n",
    "# Criar uma \"zona de exclus√£o\" ao redor dos pontos de presen√ßa\n",
    "buffer_presenca = gdf_ocorrencias.geometry.buffer(0.5).unary_union\n",
    "\n",
    "# Gerar pontos aleat√≥rios dentro do pol√≠gono do Brasil\n",
    "pseudo_ausencias_points = []\n",
    "while len(pseudo_ausencias_points) < num_pseudo_ausencias:\n",
    "    minx, miny, maxx, maxy = brasil_poligono.bounds\n",
    "    random_point = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))\n",
    "    if brasil_poligono.contains(random_point) and not buffer_presenca.contains(random_point):\n",
    "        pseudo_ausencias_points.append(random_point)\n",
    "\n",
    "# Criar um GeoDataFrame para as pseudo-aus√™ncias\n",
    "gdf_pseudo_ausencias = gpd.GeoDataFrame(\n",
    "    geometry=pseudo_ausencias_points,\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "print(f\"Gerados {len(gdf_pseudo_ausencias)} pontos de pseudo-aus√™ncia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fc8d4",
   "metadata": {},
   "source": [
    "#### Criar um Conjunto de Dados de Treinamento Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para extrair valores do raster para um GeoDataFrame\n",
    "def extract_raster_values(gdf, raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        coords = [(x, y) for x, y in zip(gdf.geometry.x, gdf.geometry.y)]\n",
    "        values = [val for val in src.sample(coords)]\n",
    "    return np.array(values)\n",
    "\n",
    "# Extrair valores para presen√ßas e pseudo-aus√™ncias\n",
    "valores_presenca = extract_raster_values(gdf_ocorrencias, stack_path)\n",
    "valores_ausencia = extract_raster_values(gdf_pseudo_ausencias, stack_path)\n",
    "\n",
    "# Criar o dataset final\n",
    "X = np.vstack((valores_presenca, valores_ausencia))\n",
    "y = np.array([1] * len(valores_presenca) + [0] * len(valores_ausencia))\n",
    "\n",
    "# Nomes das features (bio1 a bio19)\n",
    "feature_names = [os.path.basename(f).split('.')[0] for f in sorted(clima_files)]\n",
    "\n",
    "# Criar um DataFrame para visualiza√ß√£o\n",
    "df_treinamento = pd.DataFrame(X, columns=feature_names)\n",
    "df_treinamento['presenca'] = y\n",
    "\n",
    "print(\"Conjunto de dados de treinamento criado:\")\n",
    "print(df_treinamento.head())\n",
    "print(f\"\\nShape de X: {X.shape}, Shape de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ab8c9",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ab8e5",
   "metadata": {},
   "source": [
    "#### Dividir os Dados e Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Inicializar o modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "print(\"Treinando o modelo Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Treinamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45305a1b",
   "metadata": {},
   "source": [
    "#### Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb99024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previs√µes no conjunto de teste\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Avaliar a acur√°cia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acur√°cia do modelo no conjunto de teste: {accuracy:.2f}\")\n",
    "\n",
    "# Mostrar um relat√≥rio de classifica√ß√£o detalhado\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Analisar a import√¢ncia de cada vari√°vel clim√°tica\n",
    "importancias = pd.DataFrame({\n",
    "    'variavel': feature_names,\n",
    "    'importancia': rf_model.feature_importances_\n",
    "}).sort_values('importancia', ascending=False)\n",
    "\n",
    "print(\"\\nImport√¢ncia das Vari√°veis Clim√°ticas:\")\n",
    "print(importancias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fe838",
   "metadata": {},
   "source": [
    "### Previs√£o para cen√°rios futuros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bec70a",
   "metadata": {},
   "source": [
    "#### Definir a Fun√ß√£o de Previs√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d409ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_cenario(cenario_folder_path, modelo, output_path):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para prever a adequabilidade de habitat para um cen√°rio clim√°tico futuro.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessando cen√°rio em: {cenario_folder_path}\")\n",
    "    \n",
    "    cenario_files = sorted(glob.glob(os.path.join(cenario_folder_path, \"*.tif\")))\n",
    "    \n",
    "    with rasterio.open(cenario_files[0]) as src:\n",
    "        profile = src.profile\n",
    "        \n",
    "    raster_data = np.stack([rasterio.open(f).read(1) for f in cenario_files])\n",
    "    height, width = raster_data.shape[1], raster_data.shape[2]\n",
    "    raster_data_reshaped = raster_data.reshape((len(cenario_files), -1)).T\n",
    "    \n",
    "    # Tratar valores NoData\n",
    "    nodata_val = -9999.0\n",
    "    raster_data_reshaped[raster_data_reshaped == nodata_val] = np.nan\n",
    "    col_mean = np.nanmean(raster_data_reshaped, axis=0)\n",
    "    inds = np.where(np.isnan(raster_data_reshaped))\n",
    "    raster_data_reshaped[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "    print(\"Realizando a previs√£o...\")\n",
    "    previsao = modelo.predict_proba(raster_data_reshaped)[:, 1]\n",
    "    previsao_mapa = previsao.reshape((height, width))\n",
    "    \n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(previsao_mapa.astype(rasterio.float32), 1)\n",
    "        \n",
    "    print(f\"Mapa de adequabilidade salvo em: {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fa08d",
   "metadata": {},
   "source": [
    "#### Executar as Previs√µes para todos os Per√≠odos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ec1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VERS√ÉO CORRIGIDA COM OS NOMES REAIS DAS PASTAS ---\n",
    "\n",
    "# Lista dos per√≠odos futuros com os nomes EXATOS das suas pastas\n",
    "periodos_futuros = [\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100\"\n",
    "]\n",
    "\n",
    "# Loop para prever e salvar cada cen√°rio\n",
    "for periodo in periodos_futuros:\n",
    "    # O caminho para a pasta do cen√°rio √© constru√≠do dinamicamente\n",
    "    cenario_path = BASE_DIR / 'data' / 'clima_futuro' / periodo\n",
    "    \n",
    "    # O nome do arquivo de sa√≠da tamb√©m usa o nome do per√≠odo\n",
    "    output_filename = f\"previsao_trigona_{periodo}.tif\"\n",
    "    output_path = PASTA_PREVISOES / output_filename\n",
    "    \n",
    "    # Chamar a fun√ß√£o de previs√£o\n",
    "    prever_cenario(cenario_path, rf_model, output_path)\n",
    "\n",
    "print(\"\\nüéâ Todos os cen√°rios futuros foram processados e salvos na pasta 'data/previsoes_futuras/'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd251840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def detectar_mapas_brasil():\n",
    "    \"\"\"Detecta automaticamente os mapas mascarados do Brasil\"\"\"\n",
    "    mapas_encontrados = {}\n",
    "    \n",
    "    # Procurar mapas de distribui√ß√£o atual\n",
    "    atual_files = glob.glob(\"mapa_predito_atual_*_brasil.tif\")\n",
    "    if atual_files:\n",
    "        mapas_encontrados[\"atual\"] = atual_files[0]\n",
    "    \n",
    "    # Procurar mapas de distribui√ß√£o futura\n",
    "    futuro_files = glob.glob(\"mapa_predito_futuro*_brasil.tif\")\n",
    "    if futuro_files:\n",
    "        mapas_encontrados[\"futuro\"] = futuro_files[0]\n",
    "    \n",
    "    # Procurar mapas de mudan√ßa\n",
    "    mudanca_files = glob.glob(\"mapa_mudanca_*_brasil.tif\")\n",
    "    if mudanca_files:\n",
    "        mapas_encontrados[\"mudanca\"] = mudanca_files[0]\n",
    "    \n",
    "    return mapas_encontrados\n",
    "\n",
    "def visualizar_mapa(tif_path, titulo, salvar=True, escala_padronizada=True):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(1).astype(float)\n",
    "\n",
    "        # Trata valores nodata\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = np.nan\n",
    "\n",
    "        # Obt√©m valores m√≠nimo e m√°ximo reais para estat√≠sticas\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        if len(valid_data) == 0:\n",
    "            print(f\"‚ùå Nenhum dado v√°lido encontrado em {titulo}\")\n",
    "            return\n",
    "            \n",
    "        v_min_real = np.nanmin(valid_data)\n",
    "        v_max_real = np.nanmax(valid_data)\n",
    "        \n",
    "        # Calcula estat√≠sticas b√°sicas\n",
    "        mean = np.nanmean(valid_data)\n",
    "        std = np.nanstd(valid_data)\n",
    "        \n",
    "        print(f\"üìä Estat√≠sticas para {titulo}:\")\n",
    "        print(f\"   - Min: {v_min_real:.4f}, Max: {v_max_real:.4f}, M√©dia: {mean:.4f}, Desvio: {std:.4f}\")\n",
    "        \n",
    "        # Define escala de visualiza√ß√£o\n",
    "        if escala_padronizada:\n",
    "            if \"mudan√ßa\" in titulo.lower() or \"mudanca\" in titulo.lower():\n",
    "                # Para mapas de mudan√ßa: escala sim√©trica baseada no m√°ximo absoluto global\n",
    "                abs_max = max(abs(v_min_real), abs(v_max_real))\n",
    "                # Usar uma escala padr√£o de -0.8 a +0.8 para mudan√ßas\n",
    "                v_min, v_max = -0.8, 0.8\n",
    "                cmap = plt.cm.RdBu_r  # Vermelho = perda, Azul = ganho\n",
    "                label = 'Mudan√ßa na Probabilidade'\n",
    "                print(f\"   üìè Escala padronizada para mudan√ßa: {v_min} a {v_max}\")\n",
    "            else:\n",
    "                # Para mapas de probabilidade: escala padronizada 0-1\n",
    "                v_min, v_max = 0.0, 1.0\n",
    "                cmap = plt.cm.viridis\n",
    "                label = 'Probabilidade de Adequabilidade'\n",
    "                print(f\"   üìè Escala padronizada para probabilidade: {v_min} a {v_max}\")\n",
    "        else:\n",
    "            # Escala din√¢mica baseada nos dados\n",
    "            v_min, v_max = v_min_real, v_max_real\n",
    "            if \"mudan√ßa\" in titulo.lower() or \"mudanca\" in titulo.lower():\n",
    "                cmap = plt.cm.RdBu_r\n",
    "                label = 'Mudan√ßa na Probabilidade'\n",
    "            else:\n",
    "                cmap = plt.cm.viridis\n",
    "                label = 'Probabilidade de Adequabilidade'\n",
    "            print(f\"   üìè Escala din√¢mica: {v_min:.4f} a {v_max:.4f}\")\n",
    "        \n",
    "        # Configura visualiza√ß√£o\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Cria o mapa\n",
    "        im = plt.imshow(data, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "        \n",
    "        # Adiciona t√≠tulo e legenda\n",
    "        plt.title(titulo, fontsize=16, pad=20)\n",
    "        plt.axis('off')\n",
    "        cbar = plt.colorbar(im, label=label, shrink=0.7)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        # Adiciona informa√ß√µes sobre valores reais e escala\n",
    "        info_text = f\"Valores reais: {v_min_real:.4f} a {v_max_real:.4f}\\nM√©dia: {mean:.4f} ¬± {std:.4f}\"\n",
    "        if escala_padronizada:\n",
    "            info_text += f\"\\nEscala padronizada: {v_min} a {v_max}\"\n",
    "        \n",
    "        plt.annotate(info_text, \n",
    "                     xy=(0.02, 0.02), xycoords='figure fraction', \n",
    "                     fontsize=11, color='black', backgroundcolor='white',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva o mapa em alta resolu√ß√£o para o trabalho acad√™mico\n",
    "        if salvar:\n",
    "            nome_arquivo = f\"{titulo.replace(' ', '_').replace('(', '').replace(')', '')}.png\"\n",
    "            plt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\n",
    "            print(f\"üíæ Mapa salvo como: {nome_arquivo}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def visualizar_mapa_diferenca(atual_path, futuro_path, escala_padronizada=True):\n",
    "    \"\"\"Cria um mapa de diferen√ßa entre distribui√ß√£o futura e atual\"\"\"\n",
    "    \n",
    "    if not os.path.exists(atual_path) or not os.path.exists(futuro_path):\n",
    "        print(\"‚ùå Arquivos de mapa n√£o encontrados para calcular diferen√ßa\")\n",
    "        return\n",
    "    \n",
    "    with rasterio.open(atual_path) as src_atual, rasterio.open(futuro_path) as src_futuro:\n",
    "        data_atual = src_atual.read(1).astype(float)\n",
    "        data_futuro = src_futuro.read(1).astype(float)\n",
    "        \n",
    "        # Trata valores nodata\n",
    "        if src_atual.nodata is not None:\n",
    "            data_atual[data_atual == src_atual.nodata] = np.nan\n",
    "        if src_futuro.nodata is not None:\n",
    "            data_futuro[data_futuro == src_futuro.nodata] = np.nan\n",
    "        \n",
    "        # Calcula diferen√ßa\n",
    "        data_diff = data_futuro - data_atual\n",
    "        \n",
    "        # Configurar visualiza√ß√£o\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Paleta divergente para mudan√ßas (vermelho = perda, azul = ganho)\n",
    "        cmap = plt.cm.RdBu_r\n",
    "        \n",
    "        # Determinar limite para visualiza√ß√£o\n",
    "        valid_diff = data_diff[~np.isnan(data_diff)]\n",
    "        if len(valid_diff) == 0:\n",
    "            print(\"‚ùå Nenhum dado v√°lido para calcular diferen√ßa\")\n",
    "            return\n",
    "        \n",
    "        v_min_real = np.nanmin(data_diff)\n",
    "        v_max_real = np.nanmax(data_diff)\n",
    "        \n",
    "        if escala_padronizada:\n",
    "            # Escala padronizada para mudan√ßas\n",
    "            v_min, v_max = -0.8, 0.8\n",
    "        else:\n",
    "            # Escala din√¢mica sim√©trica\n",
    "            abs_max = max(abs(v_min_real), abs(v_max_real))\n",
    "            v_min, v_max = -abs_max, abs_max\n",
    "        \n",
    "        im = plt.imshow(data_diff, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "        \n",
    "        plt.title(\"Mudan√ßa na Distribui√ß√£o (Futuro - Atual)\", fontsize=16, pad=20)\n",
    "        plt.axis('off')\n",
    "        cbar = plt.colorbar(im, label='Mudan√ßa na Probabilidade', shrink=0.7)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        # Calcular estat√≠sticas da diferen√ßa\n",
    "        mean_diff = np.nanmean(data_diff)\n",
    "        perc_loss = np.sum(data_diff < -0.1) / np.sum(~np.isnan(data_diff)) * 100\n",
    "        perc_gain = np.sum(data_diff > 0.1) / np.sum(~np.isnan(data_diff)) * 100\n",
    "        \n",
    "        # Adiciona informa√ß√µes sobre valores\n",
    "        info_text = (f\"Valores reais: {v_min_real:.4f} a {v_max_real:.4f}\\n\"\n",
    "                     f\"M√©dia da mudan√ßa: {mean_diff:.4f}\\n\"\n",
    "                     f\"√Årea com perda (< -0.1): {perc_loss:.1f}%\\n\"\n",
    "                     f\"√Årea com ganho (> 0.1): {perc_gain:.1f}%\")\n",
    "        \n",
    "        if escala_padronizada:\n",
    "            info_text += f\"\\nEscala padronizada: {v_min} a {v_max}\"\n",
    "        \n",
    "        plt.annotate(info_text, xy=(0.02, 0.02), xycoords='figure fraction', \n",
    "                     fontsize=11, color='black', backgroundcolor='white',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva o mapa\n",
    "        plt.savefig(\"Mudanca_na_Distribuicao.png\", dpi=300, bbox_inches='tight')\n",
    "        print(f\"üíæ Mapa de mudan√ßa salvo como: Mudanca_na_Distribuicao.png\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Detectar mapas automaticamente\n",
    "    mapas = detectar_mapas_brasil()\n",
    "    \n",
    "    if not mapas:\n",
    "        print(\"‚ùå Nenhum mapa mascarado encontrado!\")\n",
    "        print(\"Execute primeiro:\")\n",
    "        print(\"1. python gerar_mapas_ajustados.py\")\n",
    "        print(\"2. python mascarar_brasil.py\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"üìÇ Mapas detectados:\")\n",
    "    for tipo, arquivo in mapas.items():\n",
    "        print(f\"  - {tipo}: {arquivo}\")\n",
    "    \n",
    "    # Perguntar sobre padroniza√ß√£o\n",
    "    print(\"\\nüé® Escolha o tipo de escala para visualiza√ß√£o:\")\n",
    "    print(\"1. Escala padronizada (0-1 para probabilidades, -0.8 a +0.8 para mudan√ßas)\")\n",
    "    print(\"2. Escala din√¢mica (baseada nos valores dos dados)\")\n",
    "    opcao_escala = input(\"Op√ß√£o (1 ou 2) [padr√£o=1]: \").strip() or \"1\"\n",
    "    \n",
    "    escala_padronizada = opcao_escala == \"1\"\n",
    "    \n",
    "    if escala_padronizada:\n",
    "        print(\"‚úÖ Usando escalas padronizadas para compara√ß√£o cient√≠fica\")\n",
    "    else:\n",
    "        print(\"‚úÖ Usando escalas din√¢micas para visualiza√ß√£o detalhada\")\n",
    "    \n",
    "    # Visualizar mapas de distribui√ß√£o\n",
    "    if \"atual\" in mapas:\n",
    "        print(f\"\\nüìç Exibindo: Distribui√ß√£o Atual\")\n",
    "        # Extrair sufixo do arquivo para identificar o cen√°rio\n",
    "        nome_arquivo = os.path.basename(mapas[\"atual\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"atual\"], f\"Distribui√ß√£o Atual{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    if \"futuro\" in mapas:\n",
    "        print(f\"\\nüìç Exibindo: Distribui√ß√£o Futura\")\n",
    "        # Extrair sufixo do arquivo para identificar o cen√°rio\n",
    "        nome_arquivo = os.path.basename(mapas[\"futuro\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"futuro\"], f\"Distribui√ß√£o Futura{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    # Visualizar mapa de mudan√ßa se dispon√≠vel\n",
    "    if \"mudanca\" in mapas:\n",
    "        print(f\"\\nüìç Exibindo: Mapa de Mudan√ßa\")\n",
    "        nome_arquivo = os.path.basename(mapas[\"mudanca\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"mudanca\"], f\"Mudan√ßa na Distribui√ß√£o{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    # Se temos atual e futuro, calcular diferen√ßa manualmente se n√£o existe mapa de mudan√ßa\n",
    "    elif \"atual\" in mapas and \"futuro\" in mapas:\n",
    "        print(f\"\\nüìç Calculando mapa de diferen√ßa entre distribui√ß√£o futura e atual\")\n",
    "        visualizar_mapa_diferenca(mapas[\"atual\"], mapas[\"futuro\"], escala_padronizada=escala_padronizada)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
