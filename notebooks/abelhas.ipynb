{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb194a5",
   "metadata": {},
   "source": [
    "# Projeto Abelho Trigona Spinipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5ccfb",
   "metadata": {},
   "source": [
    "## Processar vari√°veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "def extrair_variaveis_bioclimaticas(arquivo_tif, diretorio_saida):\n",
    "    \"\"\"\n",
    "    Extrai as 19 vari√°veis bioclim√°ticas de um √∫nico arquivo .tif do WorldClim\n",
    "    e salva cada uma como um arquivo separado.\n",
    "    \n",
    "    Args:\n",
    "        arquivo_tif: Caminho para o arquivo .tif multi-banda do WorldClim\n",
    "        diretorio_saida: Diret√≥rio onde salvar os arquivos individuais\n",
    "    \"\"\"\n",
    "    os.makedirs(diretorio_saida, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processando arquivo: {arquivo_tif}\")\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(arquivo_tif) as src:\n",
    "            # Verificar n√∫mero de bandas\n",
    "            num_bandas = src.count\n",
    "            print(f\"N√∫mero de bandas detectadas: {num_bandas}\")\n",
    "            \n",
    "            if num_bandas == 1:\n",
    "                print(\"AVISO: Este arquivo tem apenas uma banda. Pode n√£o ser um arquivo multi-vari√°vel.\")\n",
    "                \n",
    "                # Extrair nome da vari√°vel do nome do arquivo\n",
    "                nome_arquivo = os.path.basename(arquivo_tif)\n",
    "                if \"bio\" in nome_arquivo.lower():\n",
    "                    # Tentar extrair n√∫mero da vari√°vel bioclim√°tica\n",
    "                    partes = nome_arquivo.lower().split(\"bio\")\n",
    "                    if len(partes) > 1:\n",
    "                        num_var = ''.join(filter(str.isdigit, partes[1]))\n",
    "                        if num_var:\n",
    "                            novo_nome = f\"bio{num_var}.tif\"\n",
    "                            arquivo_saida = os.path.join(diretorio_saida, novo_nome)\n",
    "                            \n",
    "                            # Copiar arquivo\n",
    "                            shutil.copy(arquivo_tif, arquivo_saida)\n",
    "                            print(f\"Copiado: {nome_arquivo} -> {novo_nome}\")\n",
    "                        else:\n",
    "                            print(f\"N√£o foi poss√≠vel extrair n√∫mero da vari√°vel de {nome_arquivo}\")\n",
    "                else:\n",
    "                    print(f\"Arquivo n√£o parece ser uma vari√°vel bioclim√°tica: {nome_arquivo}\")\n",
    "            else:\n",
    "                # Processar arquivo multi-banda\n",
    "                meta = src.meta.copy()\n",
    "                \n",
    "                # Atualizar metadados para arquivos de sa√≠da (uma banda)\n",
    "                meta.update({\n",
    "                    'count': 1,\n",
    "                    'driver': 'GTiff',\n",
    "                    'compress': 'lzw'\n",
    "                })\n",
    "                \n",
    "                # Extrair cada banda como um arquivo separado\n",
    "                for i in range(1, num_bandas + 1):\n",
    "                    banda = src.read(i)\n",
    "                    \n",
    "                    # Nome do arquivo de sa√≠da\n",
    "                    arquivo_saida = os.path.join(diretorio_saida, f\"bio{i}.tif\")\n",
    "                    \n",
    "                    # Salvar banda como arquivo separado\n",
    "                    with rasterio.open(arquivo_saida, 'w', **meta) as dst:\n",
    "                        dst.write(banda, 1)\n",
    "                    \n",
    "                    print(f\"Extra√≠do: banda {i} -> bio{i}.tif\")\n",
    "                \n",
    "                print(f\"Extra√ß√£o conclu√≠da: {num_bandas} vari√°veis salvas em {diretorio_saida}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao processar {arquivo_tif}: {str(e)}\")\n",
    "\n",
    "def padronizar_nomes_arquivos(diretorio_origem, diretorio_destino):\n",
    "    \"\"\"\n",
    "    Padroniza os nomes dos arquivos .tif para o formato bio1.tif, bio2.tif, etc.\n",
    "    \n",
    "    Args:\n",
    "        diretorio_origem: Diret√≥rio com os arquivos originais\n",
    "        diretorio_destino: Diret√≥rio onde salvar os arquivos renomeados\n",
    "    \"\"\"\n",
    "    os.makedirs(diretorio_destino, exist_ok=True)\n",
    "    \n",
    "    print(f\"Padronizando nomes dos arquivos em {diretorio_origem}\")\n",
    "    \n",
    "    # Padr√µes de nomes conhecidos do WorldClim\n",
    "    padroes = [\n",
    "        # WorldClim v2.1\n",
    "        {\"prefixo\": \"wc2.1_\", \"separador\": \"bio\"},\n",
    "        # CMIP6\n",
    "        {\"prefixo\": \"ssp\", \"separador\": \"bio\"},\n",
    "        {\"prefixo\": \"rcp\", \"separador\": \"bio\"},\n",
    "        # Outros formatos poss√≠veis\n",
    "        {\"prefixo\": \"\", \"separador\": \"bio\"}\n",
    "    ]\n",
    "    \n",
    "    arquivos_processados = 0\n",
    "    \n",
    "    for arquivo in glob.glob(os.path.join(diretorio_origem, \"*.tif\")):\n",
    "        nome_arquivo = os.path.basename(arquivo)\n",
    "        nome_base = os.path.splitext(nome_arquivo)[0]\n",
    "        \n",
    "        # Tentar extrair n√∫mero da vari√°vel bioclim√°tica\n",
    "        num_var = None\n",
    "        \n",
    "        for padrao in padroes:\n",
    "            if padrao[\"separador\"] in nome_base.lower():\n",
    "                partes = nome_base.lower().split(padrao[\"separador\"])\n",
    "                if len(partes) > 1:\n",
    "                    # Extrair d√≠gitos do final\n",
    "                    num_var = ''.join(filter(str.isdigit, partes[1]))\n",
    "                    if num_var:\n",
    "                        break\n",
    "        \n",
    "        if num_var:\n",
    "            novo_nome = f\"bio{num_var}.tif\"\n",
    "            arquivo_saida = os.path.join(diretorio_destino, novo_nome)\n",
    "            \n",
    "            # Copiar arquivo com novo nome\n",
    "            shutil.copy(arquivo, arquivo_saida)\n",
    "            print(f\"Renomeado: {nome_arquivo} -> {novo_nome}\")\n",
    "            arquivos_processados += 1\n",
    "        else:\n",
    "            print(f\"N√£o foi poss√≠vel extrair n√∫mero da vari√°vel de {nome_arquivo}\")\n",
    "    \n",
    "    print(f\"Padroniza√ß√£o conclu√≠da: {arquivos_processados} arquivos processados\")\n",
    "\n",
    "def verificar_consistencia(dir_atual, dir_futuro):\n",
    "    \"\"\"\n",
    "    Verifica se os mesmos arquivos existem em ambos os diret√≥rios e t√™m as mesmas dimens√µes\n",
    "    \n",
    "    Args:\n",
    "        dir_atual: Diret√≥rio com vari√°veis do clima atual\n",
    "        dir_futuro: Diret√≥rio com vari√°veis do clima futuro\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vari√°veis em comum\n",
    "    \"\"\"\n",
    "    print(f\"Verificando consist√™ncia entre {dir_atual} e {dir_futuro}\")\n",
    "    \n",
    "    arquivos_atual = set(os.path.basename(f) for f in glob.glob(os.path.join(dir_atual, \"*.tif\")))\n",
    "    arquivos_futuro = set(os.path.basename(f) for f in glob.glob(os.path.join(dir_futuro, \"*.tif\")))\n",
    "    \n",
    "    # Verificar arquivos em comum\n",
    "    comuns = arquivos_atual & arquivos_futuro\n",
    "    print(f\"Vari√°veis em comum: {len(comuns)}\")\n",
    "    \n",
    "    if len(comuns) == 0:\n",
    "        print(\"ERRO: Nenhuma vari√°vel em comum encontrada!\")\n",
    "        return []\n",
    "    \n",
    "    # Verificar dimens√µes\n",
    "    problemas = []\n",
    "    for arquivo in comuns:\n",
    "        try:\n",
    "            with rasterio.open(os.path.join(dir_atual, arquivo)) as src_atual:\n",
    "                with rasterio.open(os.path.join(dir_futuro, arquivo)) as src_futuro:\n",
    "                    if src_atual.shape != src_futuro.shape:\n",
    "                        print(f\"ALERTA: {arquivo} tem dimens√µes diferentes entre cen√°rios\")\n",
    "                        print(f\"  Atual: {src_atual.shape}, Futuro: {src_futuro.shape}\")\n",
    "                        problemas.append(arquivo)\n",
    "                    if src_atual.crs != src_futuro.crs:\n",
    "                        print(f\"ALERTA: {arquivo} tem CRS diferentes entre cen√°rios\")\n",
    "                        problemas.append(arquivo)\n",
    "        except Exception as e:\n",
    "            print(f\"ERRO ao verificar {arquivo}: {str(e)}\")\n",
    "            problemas.append(arquivo)\n",
    "    \n",
    "    # Remover arquivos problem√°ticos da lista\n",
    "    comuns_ok = [arq for arq in comuns if arq not in problemas]\n",
    "    \n",
    "    if problemas:\n",
    "        print(f\"ALERTA: {len(problemas)} vari√°veis com problemas foram removidas da lista\")\n",
    "    \n",
    "    print(f\"Vari√°veis consistentes: {len(comuns_ok)}\")\n",
    "    return sorted(list(comuns_ok))\n",
    "\n",
    "def criar_metadados(variaveis, arquivo_saida=\"metadados_variaveis.md\"):\n",
    "    \"\"\"\n",
    "    Cria um arquivo de metadados para as vari√°veis bioclim√°ticas\n",
    "    \n",
    "    Args:\n",
    "        variaveis: Lista de nomes de arquivos das vari√°veis\n",
    "        arquivo_saida: Nome do arquivo de sa√≠da\n",
    "    \"\"\"\n",
    "    descricoes = {\n",
    "        \"bio1.tif\": \"Temperatura M√©dia Anual\",\n",
    "        \"bio2.tif\": \"Amplitude M√©dia Diurna (m√©dia mensal de (temp max - temp min))\",\n",
    "        \"bio3.tif\": \"Isotermalidade (bio2/bio7) (√ó100)\",\n",
    "        \"bio4.tif\": \"Sazonalidade da Temperatura (desvio padr√£o √ó100)\",\n",
    "        \"bio5.tif\": \"Temperatura M√°xima do M√™s Mais Quente\",\n",
    "        \"bio6.tif\": \"Temperatura M√≠nima do M√™s Mais Frio\",\n",
    "        \"bio7.tif\": \"Amplitude T√©rmica Anual (bio5-bio6)\",\n",
    "        \"bio8.tif\": \"Temperatura M√©dia do Trimestre Mais √ömido\",\n",
    "        \"bio9.tif\": \"Temperatura M√©dia do Trimestre Mais Seco\",\n",
    "        \"bio10.tif\": \"Temperatura M√©dia do Trimestre Mais Quente\",\n",
    "        \"bio11.tif\": \"Temperatura M√©dia do Trimestre Mais Frio\",\n",
    "        \"bio12.tif\": \"Precipita√ß√£o Anual\",\n",
    "        \"bio13.tif\": \"Precipita√ß√£o do M√™s Mais √ömido\",\n",
    "        \"bio14.tif\": \"Precipita√ß√£o do M√™s Mais Seco\",\n",
    "        \"bio15.tif\": \"Sazonalidade da Precipita√ß√£o (coeficiente de varia√ß√£o)\",\n",
    "        \"bio16.tif\": \"Precipita√ß√£o do Trimestre Mais √ömido\",\n",
    "        \"bio17.tif\": \"Precipita√ß√£o do Trimestre Mais Seco\",\n",
    "        \"bio18.tif\": \"Precipita√ß√£o do Trimestre Mais Quente\",\n",
    "        \"bio19.tif\": \"Precipita√ß√£o do Trimestre Mais Frio\"\n",
    "    }\n",
    "    \n",
    "    with open(arquivo_saida, \"w\") as f:\n",
    "        f.write(\"# Metadados das Vari√°veis Bioclim√°ticas\\n\\n\")\n",
    "        f.write(\"| Arquivo | Descri√ß√£o | Unidade |\\n\")\n",
    "        f.write(\"|---------|-----------|--------|\\n\")\n",
    "        \n",
    "        for var in sorted(variaveis):\n",
    "            nome_base = os.path.basename(var)\n",
    "            descricao = descricoes.get(nome_base, \"Descri√ß√£o n√£o dispon√≠vel\")\n",
    "            unidade = \"¬∞C\" if int(nome_base.replace(\"bio\", \"\").split(\".\")[0]) < 12 else \"mm\"\n",
    "            f.write(f\"| {nome_base} | {descricao} | {unidade} |\\n\")\n",
    "    \n",
    "    print(f\"Metadados criados: {arquivo_saida}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fun√ß√£o principal para processar arquivos bioclim√°ticos\"\"\"\n",
    "    # Diret√≥rios\n",
    "    dir_downloads = \"downloads\"\n",
    "    dir_clima_atual = \"clima_atual\"\n",
    "    dir_clima_futuro = \"clima_futuro\"\n",
    "    \n",
    "    # Criar diret√≥rios se n√£o existirem\n",
    "    os.makedirs(dir_downloads, exist_ok=True)\n",
    "    os.makedirs(dir_clima_atual, exist_ok=True)\n",
    "    os.makedirs(dir_clima_futuro, exist_ok=True)\n",
    "    \n",
    "    # Perguntar ao usu√°rio o que deseja fazer\n",
    "    print(\"\\n===== PROCESSADOR DE VARI√ÅVEIS BIOCLIM√ÅTICAS =====\\n\")\n",
    "    print(\"Escolha uma op√ß√£o:\")\n",
    "    print(\"1. Extrair vari√°veis de arquivo .tif multi-banda\")\n",
    "    print(\"2. Padronizar nomes de arquivos existentes\")\n",
    "    print(\"3. Verificar consist√™ncia entre clima atual e futuro\")\n",
    "    print(\"4. Criar metadados para as vari√°veis\")\n",
    "    print(\"5. Executar todo o processo\")\n",
    "    print(\"6. Processar pastas que j√° cont√™m arquivos bio*.tif\")\n",
    "    print(\"0. Sair\")\n",
    "    \n",
    "    opcao = input(\"\\nOp√ß√£o: \")\n",
    "    \n",
    "    if opcao == \"1\":\n",
    "        arquivo_tif = input(\"Caminho para o arquivo .tif multi-banda: \")\n",
    "        diretorio_saida = input(\"Diret√≥rio de sa√≠da [clima_atual]: \") or \"clima_atual\"\n",
    "        extrair_variaveis_bioclimaticas(arquivo_tif, diretorio_saida)\n",
    "    \n",
    "    elif opcao == \"2\":\n",
    "        diretorio_origem = input(\"Diret√≥rio com arquivos originais: \")\n",
    "        diretorio_destino = input(\"Diret√≥rio de destino para arquivos padronizados: \")\n",
    "        padronizar_nomes_arquivos(diretorio_origem, diretorio_destino)\n",
    "    \n",
    "    elif opcao == \"3\":\n",
    "        dir_atual = input(\"Diret√≥rio com clima atual [clima_atual]: \") or \"clima_atual\"\n",
    "        dir_futuro = input(\"Diret√≥rio com clima futuro [clima_futuro]: \") or \"clima_futuro\"\n",
    "        variaveis_comuns = verificar_consistencia(dir_atual, dir_futuro)\n",
    "        \n",
    "        # Salvar lista de vari√°veis em comum\n",
    "        if variaveis_comuns:\n",
    "            with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "                for var in variaveis_comuns:\n",
    "                    f.write(f\"{var}\\n\")\n",
    "            print(f\"Lista de vari√°veis salva em variaveis_usadas.txt\")\n",
    "    \n",
    "    elif opcao == \"4\":\n",
    "        dir_variaveis = input(\"Diret√≥rio com vari√°veis [clima_atual]: \") or \"clima_atual\"\n",
    "        variaveis = [os.path.basename(f) for f in glob.glob(os.path.join(dir_variaveis, \"*.tif\"))]\n",
    "        arquivo_saida = input(\"Nome do arquivo de sa√≠da [metadados_variaveis.md]: \") or \"metadados_variaveis.md\"\n",
    "        criar_metadados(variaveis, arquivo_saida)\n",
    "    \n",
    "    elif opcao == \"5\":\n",
    "        # Perguntar caminhos dos arquivos\n",
    "        arquivo_atual = input(\"Caminho para o arquivo .tif do clima atual: \")\n",
    "        arquivo_futuro = input(\"Caminho para o arquivo .tif do clima futuro: \")\n",
    "        \n",
    "        # Extrair vari√°veis\n",
    "        if os.path.exists(arquivo_atual):\n",
    "            if os.path.isdir(arquivo_atual):\n",
    "                print(f\"AVISO: {arquivo_atual} √© um diret√≥rio, n√£o um arquivo .tif\")\n",
    "            else:\n",
    "                extrair_variaveis_bioclimaticas(arquivo_atual, dir_clima_atual)\n",
    "        else:\n",
    "            print(f\"ERRO: Arquivo {arquivo_atual} n√£o encontrado\")\n",
    "        \n",
    "        if os.path.exists(arquivo_futuro):\n",
    "            if os.path.isdir(arquivo_futuro):\n",
    "                print(f\"AVISO: {arquivo_futuro} √© um diret√≥rio, n√£o um arquivo .tif\")\n",
    "            else:\n",
    "                extrair_variaveis_bioclimaticas(arquivo_futuro, dir_clima_futuro)\n",
    "        else:\n",
    "            print(f\"ERRO: Arquivo {arquivo_futuro} n√£o encontrado\")\n",
    "        \n",
    "        # Verificar consist√™ncia\n",
    "        variaveis_comuns = verificar_consistencia(dir_clima_atual, dir_clima_futuro)\n",
    "        \n",
    "        # Salvar lista de vari√°veis em comum\n",
    "        if variaveis_comuns:\n",
    "            with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "                for var in variaveis_comuns:\n",
    "                    f.write(f\"{var}\\n\")\n",
    "            print(f\"Lista de vari√°veis salva em variaveis_usadas.txt\")\n",
    "            \n",
    "            # Criar metadados\n",
    "            criar_metadados(variaveis_comuns)\n",
    "    \n",
    "    elif opcao == \"6\":\n",
    "        print(\"\\nProcessando pastas existentes com arquivos bio*.tif\")\n",
    "        dir_atual = input(\"Diret√≥rio com clima atual [clima_atual]: \") or \"clima_atual\"\n",
    "        dir_futuro = input(\"Diret√≥rio com clima futuro [clima_futuro]: \") or \"clima_futuro\"\n",
    "        \n",
    "        # Verificar se as pastas existem\n",
    "        if not os.path.isdir(dir_atual):\n",
    "            print(f\"ERRO: Diret√≥rio {dir_atual} n√£o encontrado\")\n",
    "            return\n",
    "        if not os.path.isdir(dir_futuro):\n",
    "            print(f\"ERRO: Diret√≥rio {dir_futuro} n√£o encontrado\")\n",
    "            return\n",
    "            \n",
    "        # Verificar consist√™ncia\n",
    "        variaveis_comuns = verificar_consistencia(dir_atual, dir_futuro)\n",
    "        \n",
    "        # Salvar lista de vari√°veis em comum\n",
    "        if variaveis_comuns:\n",
    "            with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "                for var in variaveis_comuns:\n",
    "                    f.write(f\"{var}\\n\")\n",
    "            print(f\"Lista de vari√°veis salva em variaveis_usadas.txt\")\n",
    "            \n",
    "            # Criar metadados\n",
    "            criar_metadados(variaveis_comuns)\n",
    "    \n",
    "    elif opcao == \"0\":\n",
    "        print(\"Saindo...\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Op√ß√£o inv√°lida!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674a6df",
   "metadata": {},
   "source": [
    "## Ajustar Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc570fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def obter_variaveis_disponiveis():\n",
    "    \"\"\"Identifica todas as vari√°veis bioclim√°ticas dispon√≠veis em ambos cen√°rios\"\"\"\n",
    "    cli_atual = set(os.path.basename(f) for f in glob.glob(\"clima_atual/*.tif\"))\n",
    "    cli_futuro = set(os.path.basename(f) for f in glob.glob(\"clima_futuro/clima_futuro2/*.tif\"))\n",
    "    comuns = sorted(list(cli_atual & cli_futuro))\n",
    "    print(f\"‚úÖ Vari√°veis em comum: {len(comuns)}\")\n",
    "    for var in comuns:\n",
    "        print(f\"  - {var}\")\n",
    "\n",
    "    # NOVO: Verifica se os arquivos futuros est√£o corretos e tem o mesmo formato\n",
    "    try:\n",
    "        with rasterio.open(os.path.join(\"clima_atual\", comuns[0])) as src_atual:\n",
    "            shape_atual = src_atual.shape\n",
    "        with rasterio.open(os.path.join(\"clima_futuro\", comuns[0])) as src_futuro:\n",
    "            shape_futuro = src_futuro.shape\n",
    "        \n",
    "        if shape_atual != shape_futuro:\n",
    "            print(f\"‚ö†Ô∏è ALERTA: Arquivos atuais ({shape_atual}) e futuros ({shape_futuro}) t√™m dimens√µes diferentes!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao verificar dimens√µes dos arquivos: {str(e)}\")\n",
    "    \n",
    "    return comuns\n",
    "\n",
    "def stack_rasters(raster_dir, selected_files):\n",
    "    \"\"\"Empilha m√∫ltiplos rasters em um √∫nico array 3D\"\"\"\n",
    "    files = [os.path.join(raster_dir, f) for f in selected_files]\n",
    "    arrays = []\n",
    "    meta = None\n",
    "    for file in tqdm(files, desc=f\"üìö Empilhando rasters em {raster_dir}\"):\n",
    "        with rasterio.open(file) as src:\n",
    "            if meta is None:\n",
    "                meta = src.meta.copy()\n",
    "            arrays.append(src.read(1))\n",
    "    stacked = np.stack(arrays, axis=-1)\n",
    "    return stacked, meta\n",
    "\n",
    "def extract_values(coords, raster_stack, meta):\n",
    "    \"\"\"Extrai valores de raster para cada coordenada\"\"\"\n",
    "    results = []\n",
    "    for lat, lon in tqdm(coords, desc=\"üìå Extraindo valores\"):\n",
    "        row, col = rasterio.transform.rowcol(meta['transform'], lon, lat)\n",
    "        if 0 <= row < raster_stack.shape[0] and 0 <= col < raster_stack.shape[1]:\n",
    "            results.append(raster_stack[row, col])\n",
    "        else:\n",
    "            results.append([np.nan]*raster_stack.shape[2])\n",
    "    return np.array(results)\n",
    "\n",
    "def generate_pseudo_absences(clima, meta, pres_coords, n_samples, min_dist_km=30):\n",
    "    \"\"\"Gera pontos de pseudo-aus√™ncia longe das presen√ßas conhecidas\"\"\"\n",
    "    absences = []\n",
    "    attempts = 0\n",
    "    max_attempts = n_samples * 30  # Aumentado para mais tentativas\n",
    "    \n",
    "    print(f\"üéØ Gerando {n_samples} pseudo-aus√™ncias\")\n",
    "    with tqdm(total=n_samples, desc=\"üö´ Gerando pseudo-aus√™ncias\") as pbar:\n",
    "        while len(absences) < n_samples and attempts < max_attempts:\n",
    "            # Estrat√©gia para melhor distribui√ß√£o espacial: dividir em quadrantes\n",
    "            row = np.random.randint(0, clima.shape[0])\n",
    "            col = np.random.randint(0, clima.shape[1])\n",
    "            vals = clima[row, col]\n",
    "            if np.isnan(vals).any():\n",
    "                attempts += 1\n",
    "                continue\n",
    "            lon, lat = rasterio.transform.xy(meta['transform'], row, col)\n",
    "            \n",
    "            # Verifica dist√¢ncia m√≠nima das presen√ßas (agora 30km em vez de 20km)\n",
    "            if all(geodesic((lat, lon), pc).km > min_dist_km for pc in pres_coords):\n",
    "                absences.append(vals)\n",
    "                pbar.update(1)\n",
    "            attempts += 1\n",
    "    \n",
    "    return np.array(absences)\n",
    "\n",
    "def ajustar_modelo():\n",
    "    print(\"üîÑ Iniciando ajuste do modelo para reduzir overfitting...\")\n",
    "    \n",
    "    # Obter vari√°veis dispon√≠veis\n",
    "    variaveis = obter_variaveis_disponiveis()\n",
    "    \n",
    "    if len(variaveis) <= 2:\n",
    "        print(\"‚ö†Ô∏è Apenas 2 vari√°veis bioclim√°ticas dispon√≠veis. Para melhor desempenho, adicione mais vari√°veis.\")\n",
    "    \n",
    "    # Ler ocorr√™ncias\n",
    "    print(\"üìä Lendo dados de ocorr√™ncia...\")\n",
    "    df = pd.read_csv(\"ocorrencias.csv\")\n",
    "    coords = list(zip(df[\"latitude\"], df[\"longitude\"]))\n",
    "    print(f\"‚úÖ Presen√ßas: {len(coords)}\")\n",
    "    \n",
    "    # Empilhar rasters\n",
    "    print(\"üìö Empilhando rasters...\")\n",
    "    clima_atual, meta_atual = stack_rasters(\"clima_atual\", variaveis)\n",
    "    print(f\"‚úÖ Clima atual empilhado: {clima_atual.shape}\")\n",
    "    \n",
    "    # Extrair valores para presen√ßas\n",
    "    presen√ßas = extract_values(coords, clima_atual, meta_atual)\n",
    "    \n",
    "    # Remover presen√ßas com NaN\n",
    "    nan_mask = np.isnan(presen√ßas).any(axis=1)\n",
    "    if nan_mask.any():\n",
    "        print(f\"‚ö†Ô∏è Removendo {nan_mask.sum()} presen√ßas com valores NaN\")\n",
    "        presen√ßas = presen√ßas[~nan_mask]\n",
    "        presenca_coords = [coord for i, coord in enumerate(coords) if not nan_mask[i]]\n",
    "    else:\n",
    "        presenca_coords = coords\n",
    "    \n",
    "    # Gerar pseudo-aus√™ncias\n",
    "    n_ausencias = len(presen√ßas)\n",
    "    ausencias = generate_pseudo_absences(clima_atual, meta_atual, presenca_coords, n_ausencias, min_dist_km=30)\n",
    "    \n",
    "    # Preparar dados para treinamento\n",
    "    X = np.vstack((presen√ßas, ausencias))\n",
    "    y = np.array([1]*len(presen√ßas) + [0]*len(ausencias))\n",
    "    \n",
    "    # Normalizar dados\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Dividir em treino/teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2)\n",
    "    \n",
    "    # Treinar modelo com par√¢metros para prevenir overfitting\n",
    "    print(\"üîß Treinando modelo com par√¢metros para reduzir overfitting...\")\n",
    "    \n",
    "    # Par√¢metros mais conservadores para evitar overfitting\n",
    "    # - Aumentando min_samples_leaf ainda mais\n",
    "    # - Limitando max_depth para evitar √°rvores muito profundas\n",
    "    # - Reduzindo n√∫mero de √°rvores para evitar memoriza√ß√£o\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=50,          # Menos √°rvores (era 100)\n",
    "        min_samples_leaf=30,      # Muito maior (era 10)\n",
    "        max_depth=10,             # Mais limitado (era 15)\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    test_acc = rf.score(X_test, y_test)\n",
    "    print(f\"‚úÖ Acur√°cia no teste: {test_acc:.3f}\")\n",
    "    \n",
    "    # Salvar modelo\n",
    "    print(\"üíæ Salvando modelo e scaler...\")\n",
    "    joblib.dump(rf, \"modelo_ajustado.pkl\")\n",
    "    joblib.dump(scaler, \"scaler_ajustado.pkl\")\n",
    "    joblib.dump(variaveis, \"variaveis_usadas.pkl\")\n",
    "    \n",
    "    # Salvar lista de vari√°veis\n",
    "    with open(\"variaveis_usadas.txt\", \"w\") as f:\n",
    "        for var in variaveis:\n",
    "            f.write(f\"{var}\\n\")\n",
    "    \n",
    "    print(\"‚úÖ Modelo ajustado! Para gerar os novos mapas, execute:\")\n",
    "    print(\"1. python gerar_mapas_ajustados.py\")\n",
    "    print(\"2. python mascarar_brasil.py\")\n",
    "    print(\"3. python visualizar_mapas.py\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ajustar_modelo() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ab8c9",
   "metadata": {},
   "source": [
    "## Gerar Mapas Ajustados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def carregar_arquivos():\n",
    "    \"\"\"Carrega modelo, scaler e lista de vari√°veis\"\"\"\n",
    "    if not os.path.exists(\"modelo_ajustado.pkl\"):\n",
    "        print(\"‚ùå Modelo ajustado n√£o encontrado. Execute ajustar_modelo.py primeiro.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    modelo = joblib.load(\"modelo_ajustado.pkl\")\n",
    "    scaler = joblib.load(\"scaler_ajustado.pkl\")\n",
    "    \n",
    "    if os.path.exists(\"variaveis_usadas.pkl\"):\n",
    "        variaveis = joblib.load(\"variaveis_usadas.pkl\")\n",
    "    else:\n",
    "        # Fallback para arquivo de texto\n",
    "        with open(\"variaveis_usadas.txt\", \"r\") as f:\n",
    "            variaveis = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return modelo, scaler, variaveis\n",
    "\n",
    "def stack_rasters(raster_dir, selected_files):\n",
    "    \"\"\"Empilha m√∫ltiplos rasters em um √∫nico array 3D\"\"\"\n",
    "    files = [os.path.join(raster_dir, f) for f in selected_files]\n",
    "    arrays = []\n",
    "    meta = None\n",
    "    shape_ref = None\n",
    "    \n",
    "    # Primeiro, verificar as dimens√µes de todos os arquivos\n",
    "    print(f\"üîç Verificando consist√™ncia dos arquivos em {raster_dir}...\")\n",
    "    for file in files:\n",
    "        with rasterio.open(file) as src:\n",
    "            if shape_ref is None:\n",
    "                shape_ref = src.shape\n",
    "                print(f\"  üìè Dimens√µes esperadas: {shape_ref}\")\n",
    "            elif src.shape != shape_ref:\n",
    "                print(f\"  ‚ö†Ô∏è ALERTA: {os.path.basename(file)} tem dimens√µes diferentes: {src.shape}\")\n",
    "                return None, None\n",
    "    \n",
    "    # Se passou na verifica√ß√£o, empilhar os rasters\n",
    "    for file in tqdm(files, desc=f\"üìö Empilhando rasters em {raster_dir}\"):\n",
    "        with rasterio.open(file) as src:\n",
    "            if meta is None:\n",
    "                meta = src.meta.copy()\n",
    "            data = src.read(1)\n",
    "            # Verificar se h√° valores v√°lidos\n",
    "            if np.all(np.isnan(data)):\n",
    "                print(f\"  ‚ö†Ô∏è ALERTA: {os.path.basename(file)} cont√©m apenas valores NaN\")\n",
    "            arrays.append(data)\n",
    "    \n",
    "    stacked = np.stack(arrays, axis=-1)\n",
    "    return stacked, meta\n",
    "\n",
    "def predizer_mapa(modelo, scaler, clima, meta, nome_saida):\n",
    "    \"\"\"Prediz probabilidade de ocorr√™ncia para cada pixel\"\"\"\n",
    "    print(f\"üó∫Ô∏è Projetando distribui√ß√£o para: {nome_saida}\")\n",
    "    \n",
    "    # Preparar dados\n",
    "    shape_original = clima.shape[:2]\n",
    "    clima_reshaped = clima.reshape(-1, clima.shape[2])\n",
    "    \n",
    "    # Identificar valores v√°lidos (n√£o-NaN)\n",
    "    valid_mask = ~np.isnan(clima_reshaped).any(axis=1)\n",
    "    valid_indices = np.where(valid_mask)[0]\n",
    "    \n",
    "    # Inicializar mapa de predi√ß√£o com NaN\n",
    "    pred_map = np.full(clima_reshaped.shape[0], np.nan)\n",
    "    \n",
    "    # Aplicar scaler e prever apenas para pixels v√°lidos\n",
    "    if len(valid_indices) > 0:\n",
    "        print(f\"‚úÖ Predizendo {len(valid_indices)} pixels v√°lidos...\")\n",
    "        valid_data = clima_reshaped[valid_indices]\n",
    "        valid_data_scaled = scaler.transform(valid_data)\n",
    "        \n",
    "        # Processar em lotes para economizar mem√≥ria\n",
    "        batch_size = 100000\n",
    "        n_batches = (len(valid_indices) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in tqdm(range(n_batches), desc=\"üîç Processando em lotes\"):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(valid_indices))\n",
    "            batch_data = valid_data_scaled[start_idx:end_idx]\n",
    "            batch_preds = modelo.predict_proba(batch_data)[:, 1]\n",
    "            pred_map[valid_indices[start_idx:end_idx]] = batch_preds\n",
    "    \n",
    "    # Redimensionar para formato original\n",
    "    pred_map = pred_map.reshape(shape_original)\n",
    "    \n",
    "    # Salvar resultado\n",
    "    print(f\"üíæ Salvando mapa em: {nome_saida}\")\n",
    "    with rasterio.open(nome_saida, \"w\", **meta) as dst:\n",
    "        dst.write(pred_map, 1)\n",
    "    \n",
    "    return pred_map\n",
    "\n",
    "def gerar_mapas():\n",
    "    # Carregar modelo e par√¢metros\n",
    "    print(\"üîç Carregando modelo ajustado...\")\n",
    "    modelo, scaler, variaveis = carregar_arquivos()\n",
    "    \n",
    "    if modelo is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ Modelo carregado com sucesso. Usando {len(variaveis)} vari√°veis bioclim√°ticas:\")\n",
    "    for var in variaveis:\n",
    "        print(f\"  - {var}\")\n",
    "    \n",
    "    # Empilhar clima atual\n",
    "    print(\"\\nüìö Empilhando clima atual...\")\n",
    "    clima_atual, meta_atual = stack_rasters(\"clima_atual\", variaveis)\n",
    "    if clima_atual is None:\n",
    "        print(\"‚ùå Erro ao empilhar clima atual. Verifique as dimens√µes dos arquivos.\")\n",
    "        return\n",
    "    print(f\"‚úÖ Clima atual empilhado: {clima_atual.shape}\")\n",
    "    \n",
    "    # Escolher qual conjunto de dados futuros usar\n",
    "    print(\"\\nüîÑ Escolha o conjunto de dados futuros:\")\n",
    "    print(\"1. clima_futuro2 (vari√°veis do bio1.tif)\")\n",
    "    print(\"2. clima_futuro3 (vari√°veis do bio2.tif)\")\n",
    "    opcao = input(\"Op√ß√£o (1 ou 2): \").strip()\n",
    "    \n",
    "    if opcao == \"1\":\n",
    "        dir_futuro = \"clima_futuro/clima_futuro2\"\n",
    "        sufixo = \"futuro2\"\n",
    "    elif opcao == \"2\":\n",
    "        dir_futuro = \"clima_futuro/clima_futuro3\"\n",
    "        sufixo = \"futuro3\"\n",
    "    else:\n",
    "        print(\"‚ùå Op√ß√£o inv√°lida!\")\n",
    "        return\n",
    "    \n",
    "    # Empilhar clima futuro\n",
    "    print(f\"\\nüìö Empilhando clima futuro de {dir_futuro}...\")\n",
    "    clima_futuro, meta_futuro = stack_rasters(dir_futuro, variaveis)\n",
    "    if clima_futuro is None:\n",
    "        print(\"‚ùå Erro ao empilhar clima futuro. Verifique as dimens√µes dos arquivos.\")\n",
    "        return\n",
    "    print(f\"‚úÖ Clima futuro empilhado: {clima_futuro.shape}\")\n",
    "    \n",
    "    # Verificar se as dimens√µes s√£o compat√≠veis\n",
    "    if clima_atual.shape != clima_futuro.shape:\n",
    "        print(f\"‚ùå Erro: Dimens√µes incompat√≠veis entre clima atual ({clima_atual.shape}) e futuro ({clima_futuro.shape})\")\n",
    "        return\n",
    "    \n",
    "    # Predizer mapas\n",
    "    mapa_atual = predizer_mapa(modelo, scaler, clima_atual, meta_atual, f\"mapa_predito_atual_{sufixo}.tif\")\n",
    "    mapa_futuro = predizer_mapa(modelo, scaler, clima_futuro, meta_futuro, f\"mapa_predito_{sufixo}.tif\")\n",
    "    \n",
    "    # Calcular mudan√ßa\n",
    "    if mapa_atual is not None and mapa_futuro is not None:\n",
    "        print(\"üìä Calculando mapa de mudan√ßa (futuro - atual)...\")\n",
    "        mapa_mudanca = mapa_futuro - mapa_atual\n",
    "        with rasterio.open(f\"mapa_mudanca_{sufixo}.tif\", \"w\", **meta_atual) as dst:\n",
    "            dst.write(mapa_mudanca, 1)\n",
    "    \n",
    "    print(\"\\n‚úÖ Mapas gerados com sucesso! Para continuar o fluxo:\")\n",
    "    print(f\"1. Execute: python mascarar_brasil.py (usando os mapas com sufixo _{sufixo})\")\n",
    "    print(\"2. Execute: python visualizar_mapas.py\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gerar_mapas() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fe838",
   "metadata": {},
   "source": [
    "## Mascarar Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d409ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def aplicar_mascara(mapa_path, shapefile_brasil, saida_path):\n",
    "    print(f\"üó∫Ô∏è Aplicando m√°scara ao arquivo: {mapa_path}\")\n",
    "\n",
    "    # Verifica se os arquivos existem\n",
    "    if not os.path.exists(mapa_path):\n",
    "        print(f\"‚ùå Arquivo de mapa n√£o encontrado: {mapa_path}\")\n",
    "        return False\n",
    "    if not os.path.exists(shapefile_brasil):\n",
    "        print(f\"‚ùå Shapefile n√£o encontrado: {shapefile_brasil}\")\n",
    "        return False\n",
    "\n",
    "    # L√™ o shapefile do Brasil\n",
    "    try:\n",
    "        print(f\"üìÇ Lendo shapefile: {shapefile_brasil}\")\n",
    "        brasil = gpd.read_file(shapefile_brasil)\n",
    "        geoms = brasil.geometry.values\n",
    "        print(f\"‚úÖ Shapefile carregado com {len(brasil)} fei√ß√µes\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler o shapefile: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # Abre o raster de entrada\n",
    "    try:\n",
    "        print(f\"üìä Lendo raster: {mapa_path}\")\n",
    "        with rasterio.open(mapa_path) as src:\n",
    "            print(f\"üìè Dimens√µes do raster: {src.width}x{src.height}\")\n",
    "            print(\"üîç Aplicando m√°scara...\")\n",
    "            out_image, out_transform = mask(src, geoms, crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao processar o raster: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # Atualiza os metadados\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"nodata\": src.nodata or -9999\n",
    "    })\n",
    "\n",
    "    # Salva o novo arquivo mascarado\n",
    "    try:\n",
    "        with rasterio.open(saida_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "        print(f\"‚úÖ Mapa salvo com m√°scara: {saida_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao salvar o resultado: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def detectar_mapas_gerados():\n",
    "    \"\"\"Detecta automaticamente os mapas gerados pelo gerar_mapas_ajustados.py\"\"\"\n",
    "    padroes = [\n",
    "        \"mapa_predito_atual_*.tif\",\n",
    "        \"mapa_predito_futuro*.tif\", \n",
    "        \"mapa_mudanca_*.tif\"\n",
    "    ]\n",
    "    \n",
    "    arquivos_encontrados = []\n",
    "    for padrao in padroes:\n",
    "        arquivos = glob.glob(padrao)\n",
    "        arquivos_encontrados.extend(arquivos)\n",
    "    \n",
    "    # Remove duplicatas e ordena\n",
    "    return sorted(list(set(arquivos_encontrados)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Caminho para o shapefile\n",
    "    shapefile_brasil = os.path.join(\"BR_UF_2024\", \"BR_UF_2024.shp\")\n",
    "    \n",
    "    # Detectar mapas gerados automaticamente\n",
    "    arquivos = detectar_mapas_gerados()\n",
    "    \n",
    "    if not arquivos:\n",
    "        print(\"‚ùå Nenhum mapa gerado encontrado!\")\n",
    "        print(\"Execute primeiro: python gerar_mapas_ajustados.py\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"üìã Mapas encontrados para processar:\")\n",
    "    for arquivo in arquivos:\n",
    "        print(f\"  - {arquivo}\")\n",
    "    \n",
    "    # Processa cada arquivo\n",
    "    sucessos = 0\n",
    "    for arquivo in tqdm(arquivos, desc=\"üó∫Ô∏è Processando mapas\"):\n",
    "        # Criar nome de sa√≠da\n",
    "        nome_base = os.path.splitext(arquivo)[0]\n",
    "        saida = f\"{nome_base}_brasil.tif\"\n",
    "        \n",
    "        if aplicar_mascara(arquivo, shapefile_brasil, saida):\n",
    "            sucessos += 1\n",
    "        print()  # Linha em branco para separar\n",
    "    \n",
    "    # Resumo\n",
    "    print(f\"‚úÖ Conclu√≠do: {sucessos}/{len(arquivos)} mapas processados com sucesso\")\n",
    "    \n",
    "    if sucessos > 0:\n",
    "        print(\"\\nüìÇ Arquivos gerados com m√°scara do Brasil:\")\n",
    "        arquivos_brasil = glob.glob(\"*_brasil.tif\")\n",
    "        for arquivo in sorted(arquivos_brasil):\n",
    "            print(f\"  ‚úÖ {arquivo}\")\n",
    "        \n",
    "        print(\"\\nüéØ Pr√≥ximos passos:\")\n",
    "        print(\"1. Execute: python visualizar_mapas.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9897401",
   "metadata": {},
   "source": [
    "## Visualizar Mapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd251840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def detectar_mapas_brasil():\n",
    "    \"\"\"Detecta automaticamente os mapas mascarados do Brasil\"\"\"\n",
    "    mapas_encontrados = {}\n",
    "    \n",
    "    # Procurar mapas de distribui√ß√£o atual\n",
    "    atual_files = glob.glob(\"mapa_predito_atual_*_brasil.tif\")\n",
    "    if atual_files:\n",
    "        mapas_encontrados[\"atual\"] = atual_files[0]\n",
    "    \n",
    "    # Procurar mapas de distribui√ß√£o futura\n",
    "    futuro_files = glob.glob(\"mapa_predito_futuro*_brasil.tif\")\n",
    "    if futuro_files:\n",
    "        mapas_encontrados[\"futuro\"] = futuro_files[0]\n",
    "    \n",
    "    # Procurar mapas de mudan√ßa\n",
    "    mudanca_files = glob.glob(\"mapa_mudanca_*_brasil.tif\")\n",
    "    if mudanca_files:\n",
    "        mapas_encontrados[\"mudanca\"] = mudanca_files[0]\n",
    "    \n",
    "    return mapas_encontrados\n",
    "\n",
    "def visualizar_mapa(tif_path, titulo, salvar=True, escala_padronizada=True):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(1).astype(float)\n",
    "\n",
    "        # Trata valores nodata\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = np.nan\n",
    "\n",
    "        # Obt√©m valores m√≠nimo e m√°ximo reais para estat√≠sticas\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        if len(valid_data) == 0:\n",
    "            print(f\"‚ùå Nenhum dado v√°lido encontrado em {titulo}\")\n",
    "            return\n",
    "            \n",
    "        v_min_real = np.nanmin(valid_data)\n",
    "        v_max_real = np.nanmax(valid_data)\n",
    "        \n",
    "        # Calcula estat√≠sticas b√°sicas\n",
    "        mean = np.nanmean(valid_data)\n",
    "        std = np.nanstd(valid_data)\n",
    "        \n",
    "        print(f\"üìä Estat√≠sticas para {titulo}:\")\n",
    "        print(f\"   - Min: {v_min_real:.4f}, Max: {v_max_real:.4f}, M√©dia: {mean:.4f}, Desvio: {std:.4f}\")\n",
    "        \n",
    "        # Define escala de visualiza√ß√£o\n",
    "        if escala_padronizada:\n",
    "            if \"mudan√ßa\" in titulo.lower() or \"mudanca\" in titulo.lower():\n",
    "                # Para mapas de mudan√ßa: escala sim√©trica baseada no m√°ximo absoluto global\n",
    "                abs_max = max(abs(v_min_real), abs(v_max_real))\n",
    "                # Usar uma escala padr√£o de -0.8 a +0.8 para mudan√ßas\n",
    "                v_min, v_max = -0.8, 0.8\n",
    "                cmap = plt.cm.RdBu_r  # Vermelho = perda, Azul = ganho\n",
    "                label = 'Mudan√ßa na Probabilidade'\n",
    "                print(f\"   üìè Escala padronizada para mudan√ßa: {v_min} a {v_max}\")\n",
    "            else:\n",
    "                # Para mapas de probabilidade: escala padronizada 0-1\n",
    "                v_min, v_max = 0.0, 1.0\n",
    "                cmap = plt.cm.viridis\n",
    "                label = 'Probabilidade de Adequabilidade'\n",
    "                print(f\"   üìè Escala padronizada para probabilidade: {v_min} a {v_max}\")\n",
    "        else:\n",
    "            # Escala din√¢mica baseada nos dados\n",
    "            v_min, v_max = v_min_real, v_max_real\n",
    "            if \"mudan√ßa\" in titulo.lower() or \"mudanca\" in titulo.lower():\n",
    "                cmap = plt.cm.RdBu_r\n",
    "                label = 'Mudan√ßa na Probabilidade'\n",
    "            else:\n",
    "                cmap = plt.cm.viridis\n",
    "                label = 'Probabilidade de Adequabilidade'\n",
    "            print(f\"   üìè Escala din√¢mica: {v_min:.4f} a {v_max:.4f}\")\n",
    "        \n",
    "        # Configura visualiza√ß√£o\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Cria o mapa\n",
    "        im = plt.imshow(data, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "        \n",
    "        # Adiciona t√≠tulo e legenda\n",
    "        plt.title(titulo, fontsize=16, pad=20)\n",
    "        plt.axis('off')\n",
    "        cbar = plt.colorbar(im, label=label, shrink=0.7)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        # Adiciona informa√ß√µes sobre valores reais e escala\n",
    "        info_text = f\"Valores reais: {v_min_real:.4f} a {v_max_real:.4f}\\nM√©dia: {mean:.4f} ¬± {std:.4f}\"\n",
    "        if escala_padronizada:\n",
    "            info_text += f\"\\nEscala padronizada: {v_min} a {v_max}\"\n",
    "        \n",
    "        plt.annotate(info_text, \n",
    "                     xy=(0.02, 0.02), xycoords='figure fraction', \n",
    "                     fontsize=11, color='black', backgroundcolor='white',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva o mapa em alta resolu√ß√£o para o trabalho acad√™mico\n",
    "        if salvar:\n",
    "            nome_arquivo = f\"{titulo.replace(' ', '_').replace('(', '').replace(')', '')}.png\"\n",
    "            plt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\n",
    "            print(f\"üíæ Mapa salvo como: {nome_arquivo}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def visualizar_mapa_diferenca(atual_path, futuro_path, escala_padronizada=True):\n",
    "    \"\"\"Cria um mapa de diferen√ßa entre distribui√ß√£o futura e atual\"\"\"\n",
    "    \n",
    "    if not os.path.exists(atual_path) or not os.path.exists(futuro_path):\n",
    "        print(\"‚ùå Arquivos de mapa n√£o encontrados para calcular diferen√ßa\")\n",
    "        return\n",
    "    \n",
    "    with rasterio.open(atual_path) as src_atual, rasterio.open(futuro_path) as src_futuro:\n",
    "        data_atual = src_atual.read(1).astype(float)\n",
    "        data_futuro = src_futuro.read(1).astype(float)\n",
    "        \n",
    "        # Trata valores nodata\n",
    "        if src_atual.nodata is not None:\n",
    "            data_atual[data_atual == src_atual.nodata] = np.nan\n",
    "        if src_futuro.nodata is not None:\n",
    "            data_futuro[data_futuro == src_futuro.nodata] = np.nan\n",
    "        \n",
    "        # Calcula diferen√ßa\n",
    "        data_diff = data_futuro - data_atual\n",
    "        \n",
    "        # Configurar visualiza√ß√£o\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Paleta divergente para mudan√ßas (vermelho = perda, azul = ganho)\n",
    "        cmap = plt.cm.RdBu_r\n",
    "        \n",
    "        # Determinar limite para visualiza√ß√£o\n",
    "        valid_diff = data_diff[~np.isnan(data_diff)]\n",
    "        if len(valid_diff) == 0:\n",
    "            print(\"‚ùå Nenhum dado v√°lido para calcular diferen√ßa\")\n",
    "            return\n",
    "        \n",
    "        v_min_real = np.nanmin(data_diff)\n",
    "        v_max_real = np.nanmax(data_diff)\n",
    "        \n",
    "        if escala_padronizada:\n",
    "            # Escala padronizada para mudan√ßas\n",
    "            v_min, v_max = -0.8, 0.8\n",
    "        else:\n",
    "            # Escala din√¢mica sim√©trica\n",
    "            abs_max = max(abs(v_min_real), abs(v_max_real))\n",
    "            v_min, v_max = -abs_max, abs_max\n",
    "        \n",
    "        im = plt.imshow(data_diff, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "        \n",
    "        plt.title(\"Mudan√ßa na Distribui√ß√£o (Futuro - Atual)\", fontsize=16, pad=20)\n",
    "        plt.axis('off')\n",
    "        cbar = plt.colorbar(im, label='Mudan√ßa na Probabilidade', shrink=0.7)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        # Calcular estat√≠sticas da diferen√ßa\n",
    "        mean_diff = np.nanmean(data_diff)\n",
    "        perc_loss = np.sum(data_diff < -0.1) / np.sum(~np.isnan(data_diff)) * 100\n",
    "        perc_gain = np.sum(data_diff > 0.1) / np.sum(~np.isnan(data_diff)) * 100\n",
    "        \n",
    "        # Adiciona informa√ß√µes sobre valores\n",
    "        info_text = (f\"Valores reais: {v_min_real:.4f} a {v_max_real:.4f}\\n\"\n",
    "                     f\"M√©dia da mudan√ßa: {mean_diff:.4f}\\n\"\n",
    "                     f\"√Årea com perda (< -0.1): {perc_loss:.1f}%\\n\"\n",
    "                     f\"√Årea com ganho (> 0.1): {perc_gain:.1f}%\")\n",
    "        \n",
    "        if escala_padronizada:\n",
    "            info_text += f\"\\nEscala padronizada: {v_min} a {v_max}\"\n",
    "        \n",
    "        plt.annotate(info_text, xy=(0.02, 0.02), xycoords='figure fraction', \n",
    "                     fontsize=11, color='black', backgroundcolor='white',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva o mapa\n",
    "        plt.savefig(\"Mudanca_na_Distribuicao.png\", dpi=300, bbox_inches='tight')\n",
    "        print(f\"üíæ Mapa de mudan√ßa salvo como: Mudanca_na_Distribuicao.png\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Detectar mapas automaticamente\n",
    "    mapas = detectar_mapas_brasil()\n",
    "    \n",
    "    if not mapas:\n",
    "        print(\"‚ùå Nenhum mapa mascarado encontrado!\")\n",
    "        print(\"Execute primeiro:\")\n",
    "        print(\"1. python gerar_mapas_ajustados.py\")\n",
    "        print(\"2. python mascarar_brasil.py\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"üìÇ Mapas detectados:\")\n",
    "    for tipo, arquivo in mapas.items():\n",
    "        print(f\"  - {tipo}: {arquivo}\")\n",
    "    \n",
    "    # Perguntar sobre padroniza√ß√£o\n",
    "    print(\"\\nüé® Escolha o tipo de escala para visualiza√ß√£o:\")\n",
    "    print(\"1. Escala padronizada (0-1 para probabilidades, -0.8 a +0.8 para mudan√ßas)\")\n",
    "    print(\"2. Escala din√¢mica (baseada nos valores dos dados)\")\n",
    "    opcao_escala = input(\"Op√ß√£o (1 ou 2) [padr√£o=1]: \").strip() or \"1\"\n",
    "    \n",
    "    escala_padronizada = opcao_escala == \"1\"\n",
    "    \n",
    "    if escala_padronizada:\n",
    "        print(\"‚úÖ Usando escalas padronizadas para compara√ß√£o cient√≠fica\")\n",
    "    else:\n",
    "        print(\"‚úÖ Usando escalas din√¢micas para visualiza√ß√£o detalhada\")\n",
    "    \n",
    "    # Visualizar mapas de distribui√ß√£o\n",
    "    if \"atual\" in mapas:\n",
    "        print(f\"\\nüìç Exibindo: Distribui√ß√£o Atual\")\n",
    "        # Extrair sufixo do arquivo para identificar o cen√°rio\n",
    "        nome_arquivo = os.path.basename(mapas[\"atual\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"atual\"], f\"Distribui√ß√£o Atual{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    if \"futuro\" in mapas:\n",
    "        print(f\"\\nüìç Exibindo: Distribui√ß√£o Futura\")\n",
    "        # Extrair sufixo do arquivo para identificar o cen√°rio\n",
    "        nome_arquivo = os.path.basename(mapas[\"futuro\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"futuro\"], f\"Distribui√ß√£o Futura{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    # Visualizar mapa de mudan√ßa se dispon√≠vel\n",
    "    if \"mudanca\" in mapas:\n",
    "        print(f\"\\nüìç Exibindo: Mapa de Mudan√ßa\")\n",
    "        nome_arquivo = os.path.basename(mapas[\"mudanca\"])\n",
    "        if \"futuro2\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro2)\"\n",
    "        elif \"futuro3\" in nome_arquivo:\n",
    "            sufixo = \" (cen√°rio futuro3)\"\n",
    "        else:\n",
    "            sufixo = \"\"\n",
    "        visualizar_mapa(mapas[\"mudanca\"], f\"Mudan√ßa na Distribui√ß√£o{sufixo}\", escala_padronizada=escala_padronizada)\n",
    "    \n",
    "    # Se temos atual e futuro, calcular diferen√ßa manualmente se n√£o existe mapa de mudan√ßa\n",
    "    elif \"atual\" in mapas and \"futuro\" in mapas:\n",
    "        print(f\"\\nüìç Calculando mapa de diferen√ßa entre distribui√ß√£o futura e atual\")\n",
    "        visualizar_mapa_diferenca(mapas[\"atual\"], mapas[\"futuro\"], escala_padronizada=escala_padronizada)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
