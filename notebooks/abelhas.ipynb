{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb194a5",
   "metadata": {},
   "source": [
    "## Algoritmo Random Forest\n",
    "- Previs√£o do posicionamento da Abelha Trigona Spinipes no per√≠odo de 2021-2040, 2041-2060, 2061-80 e 2081-2100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5ccfb",
   "metadata": {},
   "source": [
    "### Configura√ß√£o de Ambiente \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8679c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar depend√™ncias necess√°rias\n",
    "# pip install pandas geopandas rasterio scikit-learn matplotlib streamlit folium streamlit-folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72de8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente configurado e caminhos definidos automaticamente com pathlib!\n",
      "Pasta raiz do projeto encontrada: c:\\icev\\extensao\\abelhas_extensao\n",
      "Caminho do arquivo de ocorr√™ncias: c:\\icev\\extensao\\abelhas_extensao\\data\\ocorrencias.csv\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas (adicionando pathlib)\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import geometry_mask\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path  # <<< IMPORTAMOS A BIBLIOTECA PATHLIB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Ignorar avisos para uma sa√≠da mais limpa\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- DEFINI√á√ÉO AUTOM√ÅTICA DOS CAMINHOS ---\n",
    "# Esta linha m√°gica encontra o caminho da pasta do projeto automaticamente!\n",
    "# Path.cwd() pega o diret√≥rio atual (.../abelhas_extensao/notebooks)\n",
    "# .parent sobe um n√≠vel (.../abelhas_extensao)\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "# Definir os caminhos completos usando o operador / do pathlib\n",
    "OCORRENCIAS_PATH = BASE_DIR / 'data' / 'ocorrencias.csv'\n",
    "CLIMA_ATUAL_PATH = BASE_DIR / 'data' / 'clima_atual'\n",
    "BRASIL_SHAPE_PATH = BASE_DIR / 'data' / 'BR_UF_2024'\n",
    "PASTA_PREVISOES = BASE_DIR / 'data' / 'previsoes_futuras'\n",
    "\n",
    "# Criar a pasta para salvar as previs√µes, se ela n√£o existir\n",
    "PASTA_PREVISOES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Ambiente configurado e caminhos definidos automaticamente com pathlib!\")\n",
    "print(f\"Pasta raiz do projeto encontrada: {BASE_DIR}\")\n",
    "print(f\"Caminho do arquivo de ocorr√™ncias: {OCORRENCIAS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674a6df",
   "metadata": {},
   "source": [
    "### Tratamento e Carregamento dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd89c36",
   "metadata": {},
   "source": [
    "#### Carregar Dados de Ocorr√™ncia e Mapa do Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fc570fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar o arquivo 'ocorrencias.csv'...\n",
      "‚úÖ Arquivo carregado com sucesso!\n",
      "Total de pontos de ocorr√™ncia carregados: 15244\n",
      "   decimalLatitude  decimalLongitude\n",
      "0          -9.2963          -75.9972\n",
      "1         -23.4671          -56.4886\n",
      "2         -23.4671          -56.4886\n",
      "3         -23.4671          -56.4886\n",
      "4         -23.4671          -56.4886\n",
      "\n",
      "Mapa do Brasil e pontos de ocorr√™ncia carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados de ocorr√™ncia de forma robusta (VERS√ÉO FINAL CORRIGIDA)\n",
    "try:\n",
    "    print(\"Tentando carregar o arquivo 'ocorrencias.csv'...\")\n",
    "    ocorrencias_df_full = pd.read_csv(\n",
    "        OCORRENCIAS_PATH,\n",
    "        sep='\\t',                     # <<< A MUDAN√áA CHAVE! Diz ao pandas para usar tabula√ß√£o como separador.\n",
    "        comment='#',\n",
    "        on_bad_lines='skip',\n",
    "        low_memory=False,\n",
    "        encoding='utf-8-sig'\n",
    "    )\n",
    "    \n",
    "    # Agora, selecionamos apenas as colunas que nos interessamos e removemos valores nulos\n",
    "    ocorrencias_df = ocorrencias_df_full[['decimalLatitude', 'decimalLongitude']].dropna()\n",
    "    \n",
    "    print(\"‚úÖ Arquivo carregado com sucesso!\")\n",
    "    print(f\"Total de pontos de ocorr√™ncia carregados: {len(ocorrencias_df)}\")\n",
    "    print(ocorrencias_df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erro: Arquivo n√£o encontrado em '{OCORRENCIAS_PATH}'. Verifique se o caminho est√° correto.\")\n",
    "except KeyError:\n",
    "    print(\"‚ùå Erro: As colunas 'decimalLatitude' ou 'decimalLongitude' n√£o foram encontradas no arquivo.\")\n",
    "    print(\"Verifique os nomes das colunas no cabe√ßalho do seu CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ocorreu um erro inesperado ao carregar o arquivo: {e}\")\n",
    "\n",
    "# Converter o DataFrame para um GeoDataFrame\n",
    "gdf_ocorrencias = gpd.GeoDataFrame(\n",
    "    ocorrencias_df,\n",
    "    geometry=gpd.points_from_xy(ocorrencias_df.decimalLongitude, ocorrencias_df.decimalLatitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Carregar o mapa do Brasil (shapefile)\n",
    "shapefile_brasil = glob.glob(os.path.join(BRASIL_SHAPE_PATH, \"*.shp\"))[0]\n",
    "brasil_gdf = gpd.read_file(shapefile_brasil)\n",
    "\n",
    "# Unir todos os estados em um √∫nico pol√≠gono do Brasil\n",
    "brasil_poligono = brasil_gdf.unary_union\n",
    "\n",
    "print(\"\\nMapa do Brasil e pontos de ocorr√™ncia carregados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484058bf",
   "metadata": {},
   "source": [
    "#### Carregar e empilhar Dados Clim√°ticos Atuais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf3c8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rasters clim√°ticos atuais empilhados em: c:\\icev\\extensao\\abelhas_extensao\\data\\clima_atual\\clima_atual_stack.tif\n"
     ]
    }
   ],
   "source": [
    "# Listar todos os arquivos .tif de clima atual, em ordem alfab√©tica\n",
    "clima_files = sorted(glob.glob(os.path.join(CLIMA_ATUAL_PATH, \"*.tif\")))\n",
    "\n",
    "# Abrir o primeiro arquivo para obter metadados\n",
    "with rasterio.open(clima_files[0]) as src:\n",
    "    meta = src.meta\n",
    "\n",
    "# Atualizar os metadados para o novo raster empilhado (agora com 19 bandas)\n",
    "meta.update(count=len(clima_files))\n",
    "\n",
    "# Criar o caminho para o arquivo empilhado\n",
    "stack_path = os.path.join(CLIMA_ATUAL_PATH, \"clima_atual_stack.tif\")\n",
    "\n",
    "# Empilhar os rasters em um √∫nico arquivo\n",
    "with rasterio.open(stack_path, 'w', **meta) as dst:\n",
    "    for i, file in enumerate(clima_files, 1):\n",
    "        with rasterio.open(file) as src:\n",
    "            dst.write(src.read(1), i)\n",
    "\n",
    "print(f\"Rasters clim√°ticos atuais empilhados em: {stack_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd1482",
   "metadata": {},
   "source": [
    "#### Gerar Dados de Pseudo-Aus√™ncia\n",
    "- Geramos pontos de pseudo-aus√™ncia em √°reas aleat√≥rias, mas longe dos pontos de presen√ßa, para treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50c3d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerados 30488 pontos de pseudo-aus√™ncia realistas em todo o Brasil.\n"
     ]
    }
   ],
   "source": [
    "# --- VERS√ÉO MELHORADA PARA GERAR PSEUDO-AUS√äNCIAS ---\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# N√∫mero de pontos de pseudo-aus√™ncia (mantemos o mesmo n√∫mero)\n",
    "num_pseudo_ausencias = len(gdf_ocorrencias) * 2\n",
    "\n",
    "# Isso torna a tarefa de classifica√ß√£o mais realista e desafiadora\n",
    "pseudo_ausencias_points = []\n",
    "while len(pseudo_ausencias_points) < num_pseudo_ausencias:\n",
    "    # Obter limites geogr√°ficos do Brasil\n",
    "    minx, miny, maxx, maxy = brasil_poligono.bounds\n",
    "    \n",
    "    # Gerar um ponto aleat√≥rio dentro desses limites\n",
    "    random_point = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))\n",
    "    \n",
    "    # Verificar se o ponto est√° dentro do Brasil (sem a verifica√ß√£o de buffer)\n",
    "    if brasil_poligono.contains(random_point):\n",
    "        pseudo_ausencias_points.append(random_point)\n",
    "\n",
    "# Criar um GeoDataFrame para as pseudo-aus√™ncias\n",
    "gdf_pseudo_ausencias = gpd.GeoDataFrame(\n",
    "    geometry=pseudo_ausencias_points,\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "print(f\"Gerados {len(gdf_pseudo_ausencias)} pontos de pseudo-aus√™ncia realistas em todo o Brasil.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fc8d4",
   "metadata": {},
   "source": [
    "#### Criar um Conjunto de Dados de Treinamento Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b98a5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de dados de treinamento criado:\n",
      "         wc2        wc2        wc2     wc2    wc2   wc2        wc2     wc2  \\\n",
      "0  24.271093  24.590834  24.027500  2825.0  363.0  98.0  42.891392  1032.0   \n",
      "1  23.157845  26.684959  19.153584  1513.0  184.0  57.0  34.639950   520.0   \n",
      "2  23.157845  26.684959  19.153584  1513.0  184.0  57.0  34.639950   520.0   \n",
      "3  23.157845  26.684959  19.153584  1513.0  184.0  57.0  34.639950   520.0   \n",
      "4  23.157845  26.684959  19.153584  1513.0  184.0  57.0  34.639950   520.0   \n",
      "\n",
      "     wc2    wc2     wc2        wc2        wc2         wc2        wc2  \\\n",
      "0  335.0  719.0  1020.0  11.812813  87.883148   28.844713  30.877750   \n",
      "1  198.0  474.0   198.0  11.594021  57.734829  317.950592  32.429501   \n",
      "2  198.0  474.0   198.0  11.594021  57.734829  317.950592  32.429501   \n",
      "3  198.0  474.0   198.0  11.594021  57.734829  317.950592  32.429501   \n",
      "4  198.0  474.0   198.0  11.594021  57.734829  317.950592  32.429501   \n",
      "\n",
      "         wc2        wc2        wc2        wc2  presenca  \n",
      "0  17.436251  13.441500  24.330458  24.035416         1  \n",
      "1  12.348000  20.081501  25.261999  19.153584         1  \n",
      "2  12.348000  20.081501  25.261999  19.153584         1  \n",
      "3  12.348000  20.081501  25.261999  19.153584         1  \n",
      "4  12.348000  20.081501  25.261999  19.153584         1  \n",
      "\n",
      "Shape de X: (45732, 19), Shape de y: (45732,)\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para extrair valores do raster para um GeoDataFrame\n",
    "def extract_raster_values(gdf, raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        coords = [(x, y) for x, y in zip(gdf.geometry.x, gdf.geometry.y)]\n",
    "        values = [val for val in src.sample(coords)]\n",
    "    return np.array(values)\n",
    "\n",
    "# Extrair valores para presen√ßas e pseudo-aus√™ncias\n",
    "valores_presenca = extract_raster_values(gdf_ocorrencias, stack_path)\n",
    "valores_ausencia = extract_raster_values(gdf_pseudo_ausencias, stack_path)\n",
    "\n",
    "# Criar o dataset final\n",
    "X = np.vstack((valores_presenca, valores_ausencia))\n",
    "y = np.array([1] * len(valores_presenca) + [0] * len(valores_ausencia))\n",
    "\n",
    "# Nomes das features (bio1 a bio19)\n",
    "feature_names = [os.path.basename(f).split('.')[0] for f in sorted(clima_files)]\n",
    "\n",
    "# Criar um DataFrame para visualiza√ß√£o\n",
    "df_treinamento = pd.DataFrame(X, columns=feature_names)\n",
    "df_treinamento['presenca'] = y\n",
    "\n",
    "print(\"Conjunto de dados de treinamento criado:\")\n",
    "print(df_treinamento.head())\n",
    "print(f\"\\nShape de X: {X.shape}, Shape de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ab8c9",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ab8e5",
   "metadata": {},
   "source": [
    "#### Dividir os Dados e Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4743e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando o modelo com Valida√ß√£o Cruzada (5 folds)...\n",
      "\n",
      "Acur√°cias em cada fold: [0.97398054 0.97496447 0.97824185 0.97375902 0.97703914]\n",
      "Acur√°cia M√©dia (CV): 0.9756\n",
      "Desvio Padr√£o da Acur√°cia: 0.0018\n",
      "\n",
      "Treinando o modelo final com todos os dados...\n",
      "Modelo final treinado!\n",
      "\n",
      "Import√¢ncia das Vari√°veis Clim√°ticas (modelo final):\n",
      "   variavel  importancia\n",
      "14      wc2     0.122864\n",
      "13      wc2     0.110242\n",
      "2       wc2     0.082226\n",
      "11      wc2     0.074537\n",
      "7       wc2     0.066583\n",
      "16      wc2     0.056642\n",
      "0       wc2     0.054611\n",
      "17      wc2     0.050634\n",
      "12      wc2     0.044062\n",
      "6       wc2     0.042903\n",
      "18      wc2     0.041502\n",
      "1       wc2     0.037790\n",
      "4       wc2     0.036793\n",
      "15      wc2     0.036746\n",
      "3       wc2     0.034740\n",
      "9       wc2     0.033018\n",
      "10      wc2     0.030724\n",
      "5       wc2     0.021692\n",
      "8       wc2     0.021691\n"
     ]
    }
   ],
   "source": [
    "# --- VERS√ÉO MELHORADA: TREINAMENTO E AVALIA√á√ÉO ROBUSTA ---\n",
    "\n",
    "# Preparar os dados de treino (mesmo c√≥digo de antes)\n",
    "valores_presenca = extract_raster_values(gdf_ocorrencias, stack_path)\n",
    "valores_ausencia = extract_raster_values(gdf_pseudo_ausencias, stack_path)\n",
    "X = np.vstack((valores_presenca, valores_ausencia))\n",
    "y = np.array([1] * len(valores_presenca) + [0] * len(valores_ausencia))\n",
    "\n",
    "# --- Valida√ß√£o Cruzada para uma Avalia√ß√£o Mais Confi√°vel ---\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Inicializar o modelo com par√¢metros para reduzir overfitting\n",
    "# max_depth: limita a profundidade das √°rvores\n",
    "# min_samples_leaf: exige um n√∫mero m√≠nimo de amostras em uma folha\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    random_state=42, \n",
    "    n_jobs=-1, \n",
    "    class_weight='balanced',\n",
    "    max_depth=15,          # <<< NOVO: Limita a complexidade\n",
    "    min_samples_leaf=5     # <<< NOVO: Evita folhas muito espec√≠ficas\n",
    ")\n",
    "\n",
    "print(\"Avaliando o modelo com Valida√ß√£o Cruzada (5 folds)...\")\n",
    "# StratifiedKFold mant√©m a propor√ß√£o de classes em cada fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Calcular a acur√°cia em cada fold\n",
    "scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nAcur√°cias em cada fold: {scores}\")\n",
    "print(f\"Acur√°cia M√©dia (CV): {scores.mean():.4f}\")\n",
    "print(f\"Desvio Padr√£o da Acur√°cia: {scores.std():.4f}\")\n",
    "\n",
    "# Agora, treinamos o modelo final com TODOS os dados dispon√≠veis\n",
    "print(\"\\nTreinando o modelo final com todos os dados...\")\n",
    "rf_model.fit(X, y)\n",
    "print(\"Modelo final treinado!\")\n",
    "\n",
    "# Analisar a import√¢ncia das vari√°veis (com o modelo final)\n",
    "importancias = pd.DataFrame({\n",
    "    'variavel': feature_names,\n",
    "    'importancia': rf_model.feature_importances_\n",
    "}).sort_values('importancia', ascending=False)\n",
    "\n",
    "print(\"\\nImport√¢ncia das Vari√°veis Clim√°ticas (modelo final):\")\n",
    "print(importancias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fe838",
   "metadata": {},
   "source": [
    "### Previs√£o para cen√°rios futuros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bec70a",
   "metadata": {},
   "source": [
    "#### Definir a Fun√ß√£o de Previs√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d409ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_cenario(cenario_folder_path, modelo, output_path):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para prever a adequabilidade de habitat para um cen√°rio clim√°tico futuro.\n",
    "    \"\"\"\n",
    "    print(f\"Processando cen√°rio em: {cenario_folder_path}\")\n",
    "    \n",
    "    # Listar e empilhar os rasters do cen√°rio futuro\n",
    "    cenario_files = sorted(glob.glob(os.path.join(cenario_folder_path, \"*.tif\")))\n",
    "    \n",
    "    # Ler o primeiro arquivo para obter o perfil (metadados)\n",
    "    with rasterio.open(cenario_files[0]) as src:\n",
    "        profile = src.profile\n",
    "        \n",
    "    # Ler todos os dados como um array numpy 3D (bandas, altura, largura)\n",
    "    raster_data = np.stack([rasterio.open(f).read(1) for f in cenario_files])\n",
    "    \n",
    "    # Reorganizar o array para (altura, largura, bandas) para o modelo\n",
    "    height, width = raster_data.shape[1], raster_data.shape[2]\n",
    "    raster_data_reshaped = raster_data.reshape((len(cenario_files), -1)).T\n",
    "    \n",
    "    # Tratar valores NoData (geralmente -9999) para n√£o quebrar o modelo\n",
    "    nodata_val = -9999.0\n",
    "    raster_data_reshaped[raster_data_reshaped == nodata_val] = np.nan\n",
    "    \n",
    "    # Preencher NaNs com a m√©dia da coluna (vari√°vel)\n",
    "    col_mean = np.nanmean(raster_data_reshaped, axis=0)\n",
    "    inds = np.where(np.isnan(raster_data_reshaped))\n",
    "    raster_data_reshaped[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "    print(\"Realizando a previs√£o...\")\n",
    "    previsao = modelo.predict_proba(raster_data_reshaped)[:, 1]\n",
    "    \n",
    "    # Remodelar a previs√£o de volta para o formato de raster (altura, largura)\n",
    "    previsao_mapa = previsao.reshape((height, width))\n",
    "    \n",
    "    # Salvar o mapa de previs√£o como um novo GeoTIFF\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(previsao_mapa.astype(rasterio.float32), 1)\n",
    "        \n",
    "    print(f\"Mapa de adequabilidade salvo em: {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fa08d",
   "metadata": {},
   "source": [
    "#### Executar as Previs√µes para todos os Per√≠odos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d1ec1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Diagn√≥stico das Pastas de Clima Futuro ---\n",
      "\n",
      "Verificando a pasta: c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040\n",
      "‚ùå ERRO: A pasta 'wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040' n√£o existe!\n",
      "\n",
      "Verificando a pasta: c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060\n",
      "‚ùå ERRO: A pasta 'wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060' n√£o existe!\n",
      "\n",
      "Verificando a pasta: c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080\n",
      "‚ùå ERRO: A pasta 'wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080' n√£o existe!\n",
      "\n",
      "Verificando a pasta: c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100\n",
      "‚ùå ERRO: A pasta 'wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100' n√£o existe!\n",
      "\n",
      "--- SOLU√á√ÉO ---\n",
      "A pasta 'wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100' est√° com problemas. Apague-a e extraia o .zip correspondente novamente.\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE DIAGN√ìSTICO (APENAS PARA VERIFICAR) ---\n",
    "\n",
    "print(\"--- Diagn√≥stico das Pastas de Clima Futuro ---\")\n",
    "periodos_futuros = [\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100\"\n",
    "]\n",
    "clima_futuro_base_path = BASE_DIR / 'data' / 'clima_futuro'\n",
    "pasta_com_problema = None\n",
    "\n",
    "for periodo in periodos_futuros:\n",
    "    pasta_cenario = clima_futuro_base_path / periodo\n",
    "    print(f\"\\nVerificando a pasta: {pasta_cenario}\")\n",
    "    if not pasta_cenario.exists():\n",
    "        print(f\"‚ùå ERRO: A pasta '{periodo}' n√£o existe!\")\n",
    "        pasta_com_problema = periodo; continue\n",
    "    tif_files = sorted(glob.glob(os.path.join(pasta_cenario, \"*.tif\")))\n",
    "    if not tif_files:\n",
    "        print(f\"‚ùå ERRO: A pasta '{periodo}' est√° vazia ou n√£o cont√©m arquivos .tif!\")\n",
    "        pasta_com_problema = periodo\n",
    "    else:\n",
    "        print(f\"‚úÖ Encontrados {len(tif_files)} arquivos .tif na pasta '{periodo}'.\")\n",
    "\n",
    "if pasta_com_problema:\n",
    "    print(f\"\\n--- SOLU√á√ÉO ---\\nA pasta '{pasta_com_problema}' est√° com problemas. Apague-a e extraia o .zip correspondente novamente.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Todas as pastas de cen√°rio futuro parecem estar OK! Voc√™ pode prosseguir para a c√©lula de previs√£o.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07b69891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando previs√£o para o per√≠odo: wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040 ---\n",
      "‚ùå ERRO: A pasta do cen√°rio n√£o foi encontrada em 'c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040'. Pulando este per√≠odo.\n",
      "\n",
      "--- Iniciando previs√£o para o per√≠odo: wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060 ---\n",
      "‚ùå ERRO: A pasta do cen√°rio n√£o foi encontrada em 'c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060'. Pulando este per√≠odo.\n",
      "\n",
      "--- Iniciando previs√£o para o per√≠odo: wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080 ---\n",
      "‚ùå ERRO: A pasta do cen√°rio n√£o foi encontrada em 'c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080'. Pulando este per√≠odo.\n",
      "\n",
      "--- Iniciando previs√£o para o per√≠odo: wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100 ---\n",
      "‚ùå ERRO: A pasta do cen√°rio n√£o foi encontrada em 'c:\\icev\\extensao\\abelhas_extensao\\data\\clima_futuro\\wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100'. Pulando este per√≠odo.\n",
      "\n",
      "üéâ Todos os cen√°rios futuros foram processados e salvos na pasta 'data/previsoes_futuras/'!\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE EXECU√á√ÉO DAS PREVIS√ïES (APENAS PARA RODAR) ---\n",
    "\n",
    "# Lista dos per√≠odos futuros com os nomes EXATOS das suas pastas\n",
    "periodos_futuros = [\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2021-2040\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2041-2060\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2061-2080\",\n",
    "    \"wc2.1_10m_bioc_BCC-CSM2-MR_ssp245_2081-2100\"\n",
    "]\n",
    "\n",
    "# Loop para prever e salvar cada cen√°rio\n",
    "for periodo in periodos_futuros:\n",
    "    print(f\"\\n--- Iniciando previs√£o para o per√≠odo: {periodo} ---\")\n",
    "    \n",
    "    # O caminho para a pasta do cen√°rio √© constru√≠do dinamicamente\n",
    "    cenario_path = BASE_DIR / 'data' / 'clima_futuro' / periodo\n",
    "    \n",
    "    # Verifica√ß√£o de seguran√ßa para garantir que a pasta e os arquivos existem\n",
    "    if not cenario_path.exists():\n",
    "        print(f\"‚ùå ERRO: A pasta do cen√°rio n√£o foi encontrada em '{cenario_path}'. Pulando este per√≠odo.\")\n",
    "        continue\n",
    "    \n",
    "    if not glob.glob(os.path.join(cenario_path, \"*.tif\")):\n",
    "        print(f\"‚ùå ERRO: Nenhum arquivo .tif encontrado em '{cenario_path}'. Pulando este per√≠odo.\")\n",
    "        continue\n",
    "\n",
    "    # O nome do arquivo de sa√≠da tamb√©m usa o nome do per√≠odo\n",
    "    output_filename = f\"previsao_trigona_{periodo}.tif\"\n",
    "    output_path = PASTA_PREVISOES / output_filename\n",
    "    \n",
    "    # Chamar a fun√ß√£o de previs√£o\n",
    "    prever_cenario(cenario_path, rf_model, output_path)\n",
    "\n",
    "print(\"\\nüéâ Todos os cen√°rios futuros foram processados e salvos na pasta 'data/previsoes_futuras/'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
